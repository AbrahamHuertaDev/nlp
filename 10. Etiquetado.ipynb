{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![agents](images/header.jpg)\n",
    "# Etiquetado gramatical\n",
    "### Ramón Soto C. [(rsotoc@moviquest.com)](mailto:rsotoc@moviquest.com/)\n",
    "[ver en nbviewer](http://nbviewer.ipython.org/github/rsotoc/nlp/blob/master/10.%20Etiquetado.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición\n",
    "\n",
    "El **etiquetado gramatical** es el proceso de asignar a cada una de las palabras de un texto una etiqueta que describe su categoría gramatical. Se suele denominar como **POS tagging** o **POST** (por las siglas en inglés *part-of-speech tagging*). \n",
    "\n",
    "El etiquetado gramatical es una actividad muy costosa que actualmente se realiza con buen nivel de éxito (97% en inglés, aproximadamente) utilizando métodos de aprendizaje automático. Por otra parte, esta identificación de palabras permite hacer un análisis más profundo del texto. Consideremos, por ejemplo, el siguiente modelo de lexicón:\n",
    "\n",
    "![](images/lexicon.png)\n",
    "\n",
    "Aquí, representamos un registro léxico $Lx$ como:\n",
    "\n",
    "$$Lx = <l,c,A>$$\t\n",
    "\n",
    "donde $l$ es el lexema/token que estamos registrando, $c$ es la *clase semántica* a la que pertenece $l$ y $A = (a, e, g)$ es una tercia que define las actitudes (polaridad) asociadas al lexema: ($a$) es la actitud del actor que expresa la opinión, ($e$) es la opinión, posiblemente nula, del escritor que publica o comenta la opinión del actor y ($g$) la actitud general de la comunidad hacia la opinión. $a$,$e$ y $g$ toman los siguientes posibles valores en escala de Likert:\n",
    "\n",
    "$$a,e,g ∈〈neg-,neg,neutral,pos,pos+〉$$\n",
    "\n",
    "y éstas, a su vez, pueden expresarse de manera difusa:\n",
    "\n",
    "![](images\\fuzzy_opinion5.png)\n",
    "\n",
    "Esta estructura permite hacer un análisis de polaridad desde puntos de vista semántico y pragmático, pero requiere identificar el tipo de palabra utilizada.\n",
    "\n",
    "Existen diferentes algoritmos para realizar el etiquetado gramatical de un corpus. Algunos de estos métodos se basan en el uso de lexicones formados por palabras ya documentadas, siendo el más famoso el **[Corpus Penn Treebank](https://web.archive.org/web/19970614160127/http://www.cis.upenn.edu:80/~treebank/)**, desarrollado por la Universidad de Pensilvania. Otros métodos utilizan reglas gramaticales para identificar el tipo de palabra, dependiendo de su posición en el texto. En cualquier caso, se suele utilizar el estándar de etiquetado utilizado en el corpus Penn Treebank. Este estándar se basa en una colección de conceptos gramaticales no bien ordenados, como se muestra a continuación.\n",
    "\n",
    "### Categorías gramaticales\n",
    "\n",
    "Las categorías gramaticales permiten clasificar las palabras en tanto componentes de una oración. En español se reconocen nueve partes de la oración:\n",
    "\n",
    "1. Sustantivo (o nombre): es una clase de palabra cuyos referentes son clases de entidades fijas: personas, seres vivos, cosas o conceptos abstractos.\n",
    "2. Adjetivo: es una clase de palabra que actúa como modificador de un sustantivo o como atributo.\n",
    "3. Artículo: es una clase de palabra utilizada para actualizar o precisar la referencia de un sustantivo, transformándolo de desconocido y abstracto a conocido y concreto (\"*un libro*\" vs. \"*el libro*\"). \n",
    "4. Pronombre:  es una clase de palabra que sustituye a un sustantivo y realiza sus mismas funciones.\n",
    "5. Verbo: El Verbo es una clase de palabra que funciona como núcleo del predicado de una oración. Expresa acción, movimiento, existencia, consecución, condición o estado del sujeto. \n",
    "6. Adverbio: es una clase de palabra que tiene la función de modificar verbos (ven **aquí**), adverbios (**demasiado** tarde) o adjetivos (**muy** inteligente). Expresan circunstancias, como pueden ser modo, lugar, tiempo, cantidad, afirmación, duda, etc.\n",
    "7. Interjección: es una clase de palabra que equivale a una oración completa que expresa un sentimiento vivo (¡*ay*!), una llamada enérgica (¡*hey*!) o que describen, elementalmente, una acción (¡*zas*!, ¡*pum*!).\n",
    "8. Preposición: es una clase de palabra que une palabras o sintagmas dentro de una oración: *a, ante, bajo, cabe, con, contra, de, desde, entre, hacia*, etc.\n",
    "9. Conjunción: es una clase de palabra que funciona como enlace entre palabras (José **y** María), sintagmas (Mi perro **y** el tuyo) u oraciones (luchar **para** ganar).\n",
    "\n",
    "En la lingüística moderna, esta clasificación se considera obsoleta y se ha reemplazado por una clasificación funcional, basada en conceptos como:\n",
    "\n",
    "1. Sintagma nominal: es un grupo de palabras cuyo núcleo es un sustantivo, un pronombre o una palabra sustantivada (el **azul** del mar).\n",
    "2. Sintagma determinante: es un tipo de sintagma en el que el núcleo sintáctico es un determinante. El complemento de un sintagma determinante es un sintagma nominal: `Sintagma determinante` $\\to$ (`Determinante`) + `Sintagma nominal`.\n",
    "3. Sintagma verbal: es un sintagma cuyo núcleo es un verbo.\n",
    "4. Complemento sintáctico: es un sintagma que completa, precisa, aclara, extiende o incrementa el significado del núcleo de otro sintagma.\n",
    "5. Determinante: es un tipo de palabra que identifica al sustantivo y precisa su significado (**aquel** gato negro).\n",
    "6. Construcción preposicional: es un sintagma constituido por una preposición (u otro tipo de adposición) que funciona como núcleo sintáctico y asigna caso al sintagma (típicamente nominal o determinante) que le sigue, como en \"libro **de física**\" o en \"viento **del norte**\".\n",
    "\n",
    "\n",
    "\n",
    "### Etiquetas utilizadas en el proyecto *Penn Treebank*\n",
    "\n",
    "El corpus *Penn Treebank* utiliza una combinación de conceptos para derivar una nomenclatura de etiquetas en forma de árbol, siendo las principales etiquetas las que se meustran a continuación:\n",
    "\n",
    "1.\t**CC** - Conjunciones coordinantes\n",
    "2.\t**CD** - Número cardinal\n",
    "3.\t**DT** - Determinante\n",
    "4.\t**EX** - Existencial (haber)\n",
    "5.\t**FW** - Palabra extranjera\n",
    "6.\t**IN** - Preposiciones o conjunciones subordinantes \n",
    "7.\t<span style=\"background-color:blue; color:white; width:100%; padding: 0 10px 0 10px;\"> **JJ** - Adjetivo</span>\n",
    "8.\t**JJR** - Adjetivo comparativo\n",
    "9.\t**JJS** - Adjetivo superlativo\n",
    "10.\t**LS** - Marcador de elemento de lista\n",
    "11.\t**MD** - Elemento auxiliar Modal\n",
    "12.\t<span style=\"background-color:blue; color:white; width:100%; padding: 0 10px 0 10px;\"> **NN** - Sustantivo singular o colectivo</span>\n",
    "13.\t**NNS** - Sustantivo plural\n",
    "14.\t**NNP** - Nombre propio, singular\n",
    "15.\t**NNPS** - Nombre propio, plural\n",
    "16.\t**PDT** - Pre Determinante\n",
    "17.\t**POS** - Marcador de genitivo posesivo\n",
    "18.\t**PRP** - Pronombre personal\n",
    "19.\t**PRP\\$** - Pronombre posesivo\n",
    "20.\t**RB** - Adverbio\n",
    "21.\t**RBR** - Adverbio comparativo\n",
    "22.\t**RBS** - Adverbio superlativo\n",
    "23.\t**RP** - Participio\n",
    "24.\t**SYM** - Símbolo\n",
    "25.\t**TO** - La palabra \"*to*\", como preposición o como marcador del infinitivo\n",
    "26.\t**UH** - Interjección\n",
    "27.\t<span style=\"background-color:blue; color:white; width:100%; padding: 0 10px 0 10px;\"> \n",
    "**VB** - Verbo, forma base </span>\n",
    "28.\t**VBD** - Verbo, pretérito\n",
    "29.\t**VBG** - Verbo, gerundio\n",
    "30.\t**VBN** - Verbo, pasado participio\n",
    "31.\t**VBP** - Verbo, singular presente, no 3a persona\n",
    "32.\t**VBZ** - Verbo, 3a persona singular presente\n",
    "33.\t**WDT** - Determinante Wh, palabra usada como determinante\n",
    "34.\t**WP** - Pronombre Wh \n",
    "35.\t**WP\\$** - Pronombre Wh  posesivo\n",
    "36.\t**WRB** - Adverbio Wh\n",
    "\n",
    "\n",
    "### Etiquetado utilizando *NLTK*\n",
    "A continuación, emplearemos un etiquetador gramatical pre entrenado incluido en el paquete **NLTK** de Python para etiquetar las palabras contenidas en la colección de revisiones de películas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>with all this stuff going down at the moment w...</td>\n",
       "      <td>[stuff, going, moment, mj, started, listening,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>the classic war of the worlds   by timothy hi...</td>\n",
       "      <td>[classic, war, worlds, timothy, hines, enterta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>the film starts with a manager  nicholas bell ...</td>\n",
       "      <td>[film, starts, manager, nicholas, bell, giving...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>it must be assumed that those who praised this...</td>\n",
       "      <td>[must, assumed, praised, film, greatest, filme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>superbly trashy and wondrously unpretentious  ...</td>\n",
       "      <td>[superbly, trashy, wondrously, unpretentious, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review  \\\n",
       "0  5814_8          1  with all this stuff going down at the moment w...   \n",
       "1  2381_9          1   the classic war of the worlds   by timothy hi...   \n",
       "2  7759_3          0  the film starts with a manager  nicholas bell ...   \n",
       "3  3630_4          0  it must be assumed that those who praised this...   \n",
       "4  9495_8          1  superbly trashy and wondrously unpretentious  ...   \n",
       "\n",
       "                                               words  \n",
       "0  [stuff, going, moment, mj, started, listening,...  \n",
       "1  [classic, war, worlds, timothy, hines, enterta...  \n",
       "2  [film, starts, manager, nicholas, bell, giving...  \n",
       "3  [must, assumed, praised, film, greatest, filme...  \n",
       "4  [superbly, trashy, wondrously, unpretentious, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movies_reviews = pd.read_csv(\"Data sets/Movies Reviews/labeledTrainData.tsv\", sep='\\t')\n",
    "movies_reviews.review = list(map(lambda row: re.sub(\"[^a-zA-Z]\", \" \", \n",
    "                                BeautifulSoup(row, \"lxml\").get_text().lower()), \n",
    "                                 movies_reviews.review))\n",
    "stops = set(stopwords.words(\"english\"))                  \n",
    "movies_reviews[\"words\"] = list(map(lambda row: [w for w in row.split() if not w in stops], \n",
    "                                   movies_reviews.review))\n",
    "display(movies_reviews.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, realizamos el etiquetado a partir del texto completo, para mantener la posición de las palabras, pero reservamos solamente las palabras que aparecen en nuestro lexicón (que, en este caso, es muy simple, pero que tratándose del lexicón de Comics, aprovecharíamos el trabajo de limpieza ya realizado). Además, eliminamos duplicados *palabra-etiqueta*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>words</th>\n",
       "      <th>tagged_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>with all this stuff going down at the moment w...</td>\n",
       "      <td>[stuff, going, moment, mj, started, listening,...</td>\n",
       "      <td>[(powerful, JJ), (think, VBP), (messages, NNS)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>the classic war of the worlds   by timothy hi...</td>\n",
       "      <td>[classic, war, worlds, timothy, hines, enterta...</td>\n",
       "      <td>[(critics, NNS), (every, DT), (succeeds, VBZ),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>the film starts with a manager  nicholas bell ...</td>\n",
       "      <td>[film, starts, manager, nicholas, bell, giving...</td>\n",
       "      <td>[(slow, JJ), (fence, NN), (opened, VBN), (spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>it must be assumed that those who praised this...</td>\n",
       "      <td>[must, assumed, praised, film, greatest, filme...</td>\n",
       "      <td>[(appear, VB), (andrews, NNS), (slow, JJ), (de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>superbly trashy and wondrously unpretentious  ...</td>\n",
       "      <td>[superbly, trashy, wondrously, unpretentious, ...</td>\n",
       "      <td>[(love, NN), (makes, VBZ), (wondrously, RB), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review  \\\n",
       "0  5814_8          1  with all this stuff going down at the moment w...   \n",
       "1  2381_9          1   the classic war of the worlds   by timothy hi...   \n",
       "2  7759_3          0  the film starts with a manager  nicholas bell ...   \n",
       "3  3630_4          0  it must be assumed that those who praised this...   \n",
       "4  9495_8          1  superbly trashy and wondrously unpretentious  ...   \n",
       "\n",
       "                                               words  \\\n",
       "0  [stuff, going, moment, mj, started, listening,...   \n",
       "1  [classic, war, worlds, timothy, hines, enterta...   \n",
       "2  [film, starts, manager, nicholas, bell, giving...   \n",
       "3  [must, assumed, praised, film, greatest, filme...   \n",
       "4  [superbly, trashy, wondrously, unpretentious, ...   \n",
       "\n",
       "                                        tagged_words  \n",
       "0  [(powerful, JJ), (think, VBP), (messages, NNS)...  \n",
       "1  [(critics, NNS), (every, DT), (succeeds, VBZ),...  \n",
       "2  [(slow, JJ), (fence, NN), (opened, VBN), (spec...  \n",
       "3  [(appear, VB), (andrews, NNS), (slow, JJ), (de...  \n",
       "4  [(love, NN), (makes, VBZ), (wondrously, RB), (...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movies_reviews[\"tagged_words\"] = list(map(lambda row, words: list(set([w for w in \n",
    "                                                       nltk.pos_tag(nltk.word_tokenize(row))\n",
    "                                                       if w[0] in words])), \n",
    "                                   movies_reviews.review, movies_reviews.words))\n",
    "display(movies_reviews.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las palabras ya etiquetadas, para una de las revisiones, son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('powerful', 'JJ'), ('think', 'VBP'), ('messages', 'NNS'), ('usually', 'RB'), ('guy', 'NN'), ('make', 'VB'), ('impressive', 'JJ'), ('car', 'NN'), ('ranted', 'VBD'), ('like', 'IN'), ('planet', 'NN'), ('press', 'NN'), ('closed', 'JJ'), ('one', 'CD'), ('boring', 'VBG'), ('guilty', 'JJ'), ('turning', 'VBG'), ('things', 'NNS'), ('latter', 'NN'), ('call', 'VB'), ('wants', 'VBZ'), ('odd', 'JJ'), ('away', 'RB'), ('hope', 'VBP'), ('well', 'RB'), ('like', 'JJ'), ('egotist', 'NN'), ('bit', 'NN'), ('complex', 'JJ'), ('girl', 'NN'), ('performing', 'VBG'), ('mj', 'VB'), ('smooth', 'JJ'), ('course', 'NN'), ('drug', 'NN'), ('speed', 'NN'), ('stupid', 'JJ'), ('really', 'RB'), ('thought', 'VBN'), ('made', 'VBD'), ('originally', 'RB'), ('bad', 'JJ'), ('either', 'CC'), ('liars', 'NNS'), ('documentary', 'NN'), ('find', 'VB'), ('visually', 'RB'), ('watched', 'VBD'), ('mind', 'NN'), ('behind', 'IN'), ('hates', 'VBZ'), ('kiddy', 'NN'), ('jackson', 'NN'), ('supplying', 'VBG'), ('watching', 'VBG'), ('insight', 'NN'), ('nah', 'VBP'), ('saint', 'NN'), ('get', 'VB'), ('wholesome', 'JJ'), ('give', 'VB'), ('mj', 'JJ'), ('subtle', 'VBN'), ('whether', 'IN'), ('remember', 'VBP'), ('started', 'VBD'), ('attention', 'NN'), ('wiz', 'NN'), ('unless', 'IN'), ('criminal', 'JJ'), ('wanted', 'VBD'), ('like', 'VBP'), ('must', 'MD'), ('working', 'VBG'), ('patience', 'NN'), ('line', 'NN'), ('want', 'VB'), ('movie', 'NN'), ('dunno', 'NN'), ('obvious', 'JJ'), ('released', 'VBN'), ('sequence', 'NN'), ('also', 'RB'), ('michael', 'NN'), ('part', 'NN'), ('stuff', 'NN'), ('directors', 'NNS'), ('doors', 'NNS'), ('convincing', 'VBG'), ('bunch', 'NN'), ('dance', 'NN'), ('different', 'JJ'), ('fact', 'NN'), ('bestest', 'JJS'), ('towards', 'IN'), ('drugs', 'NNS'), ('music', 'NN'), ('feature', 'NN'), ('kay', 'NN'), ('starts', 'VBZ'), ('minutes', 'NNS'), ('beyond', 'IN'), ('say', 'VB'), ('joe', 'NN'), ('robot', 'NN'), ('finally', 'RB'), ('fans', 'NNS'), ('eighties', 'NNS'), ('scene', 'NN'), ('cool', 'JJ'), ('moonwalker', 'NN'), ('biography', 'NN'), ('hate', 'VBP'), ('listening', 'VBG'), ('another', 'DT'), ('jackson', 'VBP'), ('see', 'VB'), ('remotely', 'VBP'), ('certain', 'JJ'), ('lord', 'NN'), ('mj', 'FW'), ('character', 'NN'), ('level', 'NN'), ('cinema', 'NN'), ('hmmm', 'VBZ'), ('etc', 'FW'), ('came', 'VBD'), ('anyway', 'RB'), ('know', 'VB'), ('demon', 'NN'), ('moment', 'NN'), ('nice', 'JJ'), ('maybe', 'RB'), ('stay', 'VB'), ('hate', 'VB'), ('kid', 'NN'), ('grace', 'VB'), ('mj', 'NN'), ('extremely', 'RB'), ('subject', 'NN'), ('michael', 'NNS'), ('talented', 'JJ'), ('plans', 'NNS'), ('buddy', 'NN'), ('innocent', 'JJ'), ('making', 'NN'), ('actual', 'JJ'), ('true', 'JJ'), ('try', 'VB'), ('know', 'VBP'), ('pesci', 'NN'), ('dead', 'JJ'), ('filming', 'VBG'), ('message', 'NN'), ('going', 'VBG'), ('overheard', 'IN'), ('excluding', 'VBG'), ('film', 'NN'), ('bottom', 'JJ'), ('feeling', 'NN'), ('would', 'MD'), ('psychopathic', 'JJ'), ('people', 'NNS'), ('let', 'VB'), ('truly', 'RB'), ('ever', 'RB'), ('sickest', 'JJ'), ('gave', 'VBD'), ('may', 'MD'), ('whole', 'JJ'), ('director', 'NN'), ('ironically', 'RB'), ('consenting', 'VBG'), ('alone', 'RB'), ('lots', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "print(movies_reviews[\"tagged_words\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El significado de cada etiqueta puede obtenerse mediante el método `nltk.help.upenn_tagset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "['messages', 'guy', 'car', 'planet', 'press', 'things', 'latter', 'egotist', 'bit', 'girl', 'course', 'drug', 'speed', 'liars', 'documentary', 'mind', 'kiddy', 'jackson', 'insight', 'saint', 'attention', 'wiz', 'patience', 'line', 'movie', 'dunno', 'sequence', 'michael', 'part', 'stuff', 'directors', 'doors', 'bunch', 'dance', 'fact', 'drugs', 'music', 'feature', 'kay', 'minutes', 'joe', 'robot', 'fans', 'eighties', 'scene', 'moonwalker', 'biography', 'lord', 'character', 'level', 'cinema', 'demon', 'moment', 'kid', 'mj', 'subject', 'michael', 'plans', 'buddy', 'making', 'pesci', 'message', 'film', 'feeling', 'people', 'director', 'lots'] \n",
      "\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "['think', 'make', 'ranted', 'boring', 'turning', 'call', 'wants', 'hope', 'performing', 'mj', 'thought', 'made', 'find', 'watched', 'hates', 'supplying', 'watching', 'nah', 'get', 'give', 'subtle', 'remember', 'started', 'wanted', 'like', 'working', 'want', 'released', 'convincing', 'starts', 'say', 'hate', 'listening', 'jackson', 'see', 'remotely', 'hmmm', 'came', 'know', 'stay', 'hate', 'grace', 'try', 'know', 'filming', 'going', 'excluding', 'let', 'gave', 'consenting'] \n",
      "\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "['powerful', 'impressive', 'closed', 'guilty', 'odd', 'like', 'complex', 'smooth', 'stupid', 'bad', 'wholesome', 'mj', 'criminal', 'obvious', 'different', 'bestest', 'cool', 'certain', 'nice', 'talented', 'innocent', 'actual', 'true', 'dead', 'bottom', 'psychopathic', 'sickest', 'whole'] \n",
      "\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "['usually', 'away', 'well', 'really', 'originally', 'visually', 'also', 'finally', 'anyway', 'maybe', 'extremely', 'truly', 'ever', 'ironically', 'alone'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NN')\n",
    "nn = []\n",
    "for word in movies_reviews[\"tagged_words\"][0]: \n",
    "    if 'NN' in word[1]: \n",
    "        nn.append(word[0])\n",
    "print(nn, \"\\n\")\n",
    "\n",
    "nltk.help.upenn_tagset('VB')\n",
    "vbg = []\n",
    "for word in movies_reviews[\"tagged_words\"][0]: \n",
    "    if 'VB' in word[1]: \n",
    "        vbg.append(word[0])\n",
    "print(vbg, \"\\n\")\n",
    "\n",
    "nltk.help.upenn_tagset('JJ')\n",
    "jj = []\n",
    "for word in movies_reviews[\"tagged_words\"][0]: \n",
    "    if 'JJ' in word[1]: \n",
    "        jj.append(word[0])\n",
    "print(jj, \"\\n\")\n",
    "\n",
    "nltk.help.upenn_tagset('RB')\n",
    "rb = []\n",
    "for word in movies_reviews[\"tagged_words\"][0]: \n",
    "    if 'RB' in word[1]: \n",
    "        rb.append(word[0])\n",
    "print(rb, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Puede observarse la estructura de árbol (no bien documentada :-|) del corpus *Penn Treebank*, por ejemplo en el caso de los nombres, donde la etiqueta `NN`integra las etiquetas `NNS`, `NNP` y `NNPS`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "['messages', 'guy', 'car', 'planet', 'press', 'things', 'latter', 'egotist', 'bit', 'girl', 'course', 'drug', 'speed', 'liars', 'documentary', 'mind', 'kiddy', 'jackson', 'insight', 'saint', 'attention', 'wiz', 'patience', 'line', 'movie', 'dunno', 'sequence', 'michael', 'part', 'stuff', 'directors', 'doors', 'bunch', 'dance', 'fact', 'drugs', 'music', 'feature', 'kay', 'minutes', 'joe', 'robot', 'fans', 'eighties', 'scene', 'moonwalker', 'biography', 'lord', 'character', 'level', 'cinema', 'demon', 'moment', 'kid', 'mj', 'subject', 'michael', 'plans', 'buddy', 'making', 'pesci', 'message', 'film', 'feeling', 'people', 'director', 'lots'] \n",
      "\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "['messages', 'things', 'liars', 'directors', 'doors', 'drugs', 'minutes', 'fans', 'eighties', 'michael', 'plans', 'people', 'lots'] \n",
      "\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "[] \n",
      "\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "['friends'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NN')\n",
    "nn = []\n",
    "for word in movies_reviews[\"tagged_words\"][0]: \n",
    "    if 'NN' in word[1]: \n",
    "        nn.append(word[0])\n",
    "print(nn, \"\\n\")\n",
    "\n",
    "nltk.help.upenn_tagset('NNS')\n",
    "nns = []\n",
    "for word in movies_reviews[\"tagged_words\"][0]: \n",
    "    if 'NNS' in word[1]: \n",
    "        nns.append(word[0])\n",
    "print(nns, \"\\n\")\n",
    "\n",
    "nltk.help.upenn_tagset('NNP')\n",
    "nnp = []\n",
    "for word in movies_reviews[\"tagged_words\"][0]: \n",
    "    if 'NNP' in word[1]: \n",
    "        nnp.append(word[0])\n",
    "print(nnp, \"\\n\")\n",
    "\n",
    "nltk.help.upenn_tagset('NNPS')\n",
    "nnps = []\n",
    "for word in movies_reviews[\"tagged_words\"][716]: \n",
    "    if 'NNPS' in word[1]: \n",
    "        nnps.append(word[0])\n",
    "print(nnps, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los errores que arroja un etiquetador genérico pre entrenado, como el que hemos usado en esta prueba, son evidentes al observar las palabras que, por ejemplo, son etiquetadas aquí como `adjetivos`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24174 \n",
      "\n",
      "['hirsute', 'farraginous', 'embellish', 'nymphomania', 'oedpius', 'aerobic', 'geeeeeetttttttt', 'unbelief', 'underestimated', 'insult', 'brighter', 'studentpolitical', 'whorrible', 'starsky', 'puke', 'clift', 'pam', 'faux', 'jive', 'gavriil', 'inversed', 'olde', 'teal', 'specky', 'slut', 'slipknot', 'furtive', 'thinnest', 'precious', 'warned', 'forgiveable', 'unauthorized', 'unmoved', 'korea', 'danzel', 'troublesome', 'kuala', 'impecunious', 'unexplored', 'sock', 'dunwich', 'scummy', 'sensual', 'anticipated', 'playing', 'verveen', 'stucco', 'nightlife', 'injured', 'cont', 'deconstructed', 'necessity', 'unverified', 'cringeworthy', 'aetherial', 'werewolve', 'meena', 'wyllie', 'nerdier', 'purvis', 'devon', 'seperate', 'portrays', 'kinetic', 'alexandra', 'droned', 'cinematographical', 'inane', 'blackadder', 'twosome', 'bristol', 'arrogant', 'yicky', 'matter', 'philippe', 'tangier', 'hinglish', 'chelsea', 'brady', 'preoccupied', 'thepsychic', 'upbeat', 'beneficial', 'annonymous', 'bittorrent', 'matuschek', 'nimh', 'posse', 'persuasive', 'feldman', 'skoda', 'lodi', 'macchu', 'reheated', 'lama', 'future', 'uttered', 'par', 'overrule', 'detestable', 'observe', 'fta', 'devoured', 'chase', 'waylaid', 'sigh', 'impetuous', 'tribes', 'morbid', 'laurence', 'coda', 'okey', 'revised', 'fontaine', 'hottie', 'unselfishness', 'irritable', 'caw', 'coloured', 'pratt', 'trashy', 'fahrenheit', 'talledega', 'care', 'scornful', 'envy', 'sux', 'anthropomorphic', 'strengths', 'digressive', 'uplifting', 'giallo', 'sword', 'ernest', 'uninterrupted', 'forte', 'hide', 'receive', 'nested', 'novello', 'sos', 'birthday', 'filmy', 'rural', 'watching', 'tool', 'chynna', 'uomini', 'viet', 'quinn', 'donal', 'dejected', 'schoolkid', 'final', 'puts', 'unico', 'bijelic', 'yellow', 'peak', 'humanitarian', 'tonight', 'steinberg', 'esposito', 'injustice', 'offender', 'later', 'ethnic', 'pov', 'olympia', 'rko', 'afghan', 'trish', 'harassed', 'noon', 'acting', 'fetisov', 'agony', 'vial', 'manly', 'cleverness', 'cymbal', 'bremer', 'worshipful', 'gday', 'casablanka', 'uproarious', 'animated', 'applegate', 'aline', 'shetty', 'conservationist', 'conflicted', 'moto', 'hearsay', 'veritable', 'anatomy', 'aip', 'budgeted', 'discovery', 'overhead', 'resolute', 'blessed', 'wayans', 'mediumistic', 'denial', 'hoppy', 'permitted', 'rodman', 'lowlife', 'urbanized', 'speaks', 'seaside', 'dwarfed', 'rankin', 'beauty', 'scatman', 'unfolds', 'skinner', 'luckier', 'insoluble', 'messily', 'slipshod', 'slavic', 'silliness', 'lagravenese', 'xenophobicjust', 'decree', 'paagal', 'dooley', 'stabs', 'ludwig', 'bless', 'hazel', 'ahab', 'kabuki', 'motley', 'vance', 'boots', 'mcneil', 'unpredicatable', 'brownesque', 'gloriously', 'slaughter', 'gunther', 'luana', 'oppose', 'minimizing', 'issac', 'gayest', 'sunset'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "jj_movies = []\n",
    "for row in movies_reviews[\"tagged_words\"]:\n",
    "    for word in row: \n",
    "        if 'JJ' in word[1]: \n",
    "            jj_movies.append(word[0])\n",
    "jj_movies = list(set(jj_movies))\n",
    "\n",
    "print(len(jj_movies), \"\\n\")\n",
    "print(jj_movies[:250], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo similar ocurre con las demás categorías, como la identificación de verbos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28187 \n",
      "\n",
      "['embellish', 'filmaking', 'meyers', 'revamp', 'zebras', 'underestimated', 'insult', 'brighter', 'moneyed', 'glimmering', 'duccio', 'starsky', 'shift', 'puke', 'pam', 'jive', 'inversed', 'purveying', 'slut', 'mishaps', 'sculpts', 'thinnest', 'breads', 'blues', 'contemplate', 'warned', 'forays', 'vilify', 'korea', 'unmoved', 'enunciating', 'troublesome', 'experiments', 'apposed', 'unexplored', 'recordings', 'dipped', 'sock', 'caalling', 'scummy', 'coughing', 'supervillain', 'playing', 'wrangle', 'anticipated', 'katz', 'categorized', 'redlight', 'injured', 'retreated', 'wisconsin', 'corrodes', 'disinfecting', 'fund', 'kulik', 'deconstructed', 'manned', 'caters', 'bono', 'reiterated', 'meena', 'clarify', 'purvis', 'kinkle', 'devon', 'portrays', 'alexandra', 'bands', 'droned', 'incongruously', 'inane', 'blackadder', 'oppenheimer', 'overtime', 'disslikes', 'arrogant', 'matter', 'transpired', 'bullying', 'philippe', 'kleinfeld', 'tangier', 'spool', 'tojo', 'kensett', 'clutching', 'brady', 'chelsea', 'disfigures', 'reformatted', 'preoccupied', 'expense', 'courted', 'recapping', 'tending', 'matuschek', 'banning', 'bark', 'peeked', 'racism', 'lama', 'crowley', 'future', 'uttered', 'phasered', 'sets', 'par', 'kibitz', 'foleying', 'cajoled', 'observe', 'laughters', 'kirtland', 'devoured', 'cubitt', 'contextualising', 'chase', 'waylaid', 'sigh', 'tribes', 'morbid', 'laurence', 'overuse', 'revised', 'wannabees', 'fontaine', 'comparing', 'rhymer', 'camelias', 'caw', 'coloured', 'fahrenheit', 'trashy', 'care', 'envy', 'snarls', 'sux', 'dignify', 'strengths', 'uplifting', 'hide', 'sword', 'giallo', 'ernest', 'thrashes', 'receive', 'sos', 'forming', 'birthday', 'filmy', 'forsake', 'authenticating', 'watching', 'donlon', 'chynna', 'substantiate', 'quinn', 'secluding', 'weakens', 'compared', 'dejected', 'grimm', 'competing', 'venantini', 'rand', 'puts', 'sensationalize', 'altering', 'finessing', 'joslyn', 'eithier', 'yellow', 'humbleness', 'peak', 'tonight', 'publicize', 'resell', 'harnessed', 'lugacy', 'insecurities', 'cracker', 'mistrust', 'esposito', 'shedding', 'fastmoving', 'later', 'reminded', 'hasfurnished', 'placed', 'berkley', 'foretold', 'exterminated', 'reserving', 'denuded', 'olympia', 'pov', 'rko', 'alphabet', 'afghan', 'trish', 'harassed', 'acting', 'sparing', 'fetisov', 'address', 'pushing', 'agony', 'roaming', 'interconnecting', 'cleverness', 'cliches', 'etches', 'arrogated', 'animated', 'applegate', 'aline', 'emergencies', 'referred', 'bludgeon', 'conflicted', 'moto', 'adding', 'hearsay', 'forsee', 'ganged', 'premiering', 'anatomy', 'chungking', 'budgeted', 'nightmares', 'discovery', 'stitch', 'chihuahua', 'bums', 'animate', 'overhead', 'resolute', 'blessed', 'leffers', 'wayans', 'hindered', 'permitted', 'shields', 'automaticnc', 'belch', 'leered', 'acres', 'rache', 'speaks', 'abdullah'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "vb_movies = []\n",
    "for row in movies_reviews[\"tagged_words\"]:\n",
    "    for word in row: \n",
    "        if 'VB' in word[1]: \n",
    "            vb_movies.append(word[0])\n",
    "vb_movies = list(set(vb_movies))\n",
    "\n",
    "print(len(vb_movies), \"\\n\")\n",
    "print(vb_movies[:250], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y, aunque menos evidente, debido en parte a la cantidad de términos, también se presenta con los sustantivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52842 \n",
      "\n",
      "['stabs', 'thety', 'ludwig', 'bless', 'hazel', 'kabuki', 'ahab', 'motley', 'mattresses', 'trainings', 'vance', 'spandex', 'milinkovic', 'joanne', 'fanfilm', 'hamaari', 'dickerson', 'boots', 'gauche', 'byington', 'kooks', 'watcha', 'mcneil', 'lift', 'gloriously', 'bhajpai', 'rawer', 'recitals', 'slaughter', 'helter', 'gunther', 'soapbox', 'winkleman', 'luana', 'blinders', 'cowhands', 'miikes', 'sunset', 'travestite', 'posing', 'surround', 'repertoire', 'celi', 'cummings', 'cardella', 'budjet', 'gita', 'sakal', 'evangelical', 'massacessi', 'daisenso', 'infanticide', 'falafel', 'supremacy', 'karate', 'require', 'tickles', 'soup', 'range', 'supermarket', 'howell', 'dinosaurus', 'menari', 'cabo', 'yori', 'farewell', 'tip', 'claustrophobic', 'interruption', 'addison', 'confronting', 'comedus', 'vanilla', 'complain', 'taint', 'elevates', 'parlour', 'precipice', 'dunny', 'reminiscences', 'econovan', 'gatherers', 'ghetto', 'cocky', 'plywood', 'outputs', 'johnnie', 'battleships', 'tyre', 'flashing', 'suggests', 'carlyle', 'enlightenment', 'godfrey', 'sprinkling', 'lili', 'moorehead', 'interpersonal', 'colonialists', 'pigeons', 'lindstrom', 'witchmaker', 'eneide', 'chamionship', 'strutting', 'marathan', 'likelihood', 'alesia', 'panamericano', 'rolf', 'branches', 'periodicals', 'midlands', 'doofenshmirtz', 'willes', 'rupert', 'housework', 'oric', 'dorcey', 'eberts', 'ambassador', 'handsome', 'sbs', 'delhi', 'albania', 'refuge', 'poolguy', 'munich', 'markel', 'santiago', 'phonus', 'emerges', 'pankin', 'gladys', 'hara', 'eleazar', 'repulsive', 'pyro', 'boringness', 'ricochet', 'spooks', 'bello', 'leath', 'carnys', 'benvolio', 'dwar', 'torkle', 'bitty', 'commenter', 'almodovar', 'discs', 'finish', 'anti', 'monsoon', 'rald', 'velma', 'convida', 'squib', 'nuno', 'lilley', 'tayor', 'spawns', 'harewood', 'revelers', 'mckay', 'mentality', 'mahoganoy', 'communion', 'sparkles', 'rad', 'gaffikin', 'makings', 'lindley', 'thou', 'skits', 'piaf', 'fransisco', 'celie', 'ranna', 'sami', 'santamarina', 'dirrty', 'calvinist', 'barcode', 'oyster', 'dumpty', 'sheeks', 'molnar', 'dachshunds', 'jigen', 'goop', 'segal', 'riffles', 'roquevert', 'pointlessness', 'praskins', 'eleniak', 'translates', 'rigoletto', 'screwballs', 'timm', 'deponent', 'boringoverall', 'scotty', 'blucher', 'analytics', 'masturbation', 'bergman', 'kralik', 'irani', 'perm', 'driscoll', 'enterntainment', 'virulent', 'natures', 'elwes', 'lawson', 'bonejack', 'leap', 'bayreuth', 'nrw', 'liveliness', 'naturist', 'civilizations', 'waterway', 'exuberance', 'lassick', 'nonsenses', 'tusk', 'celebrate', 'baruchel', 'jaws', 'looses', 'blogs', 'magdalene', 'christianty', 'sabres', 'monosyllabic', 'plateau', 'avonlea', 'divison', 'vacillations', 'assignation', 'sosa', 'syndicates', 'bye', 'cheeky', 'crapola', 'bu', 'benchmarks'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_movies = []\n",
    "for row in movies_reviews[\"tagged_words\"]:\n",
    "    for word in row: \n",
    "        if 'NN' in word[1]: \n",
    "            nn_movies.append(word[0])\n",
    "nn_movies = list(set(nn_movies))\n",
    "\n",
    "print(len(nn_movies), \"\\n\")\n",
    "print(nn_movies[500:750], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de un etiquetador propio\n",
    "\n",
    "Entrenar un etiquetador propio es un proceso costoso y largo, ya que hay que etiquetar manualmente un lexicón. Intentemos con nuestro lexicón de Comics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file = 'Data Sets/Comics/clean_lexicon_comics.json'\n",
    "with open(file) as comics_file:\n",
    "    dict_comics = json.load(comics_file)\n",
    "comicsDf = pd.DataFrame.from_dict(dict_comics)\n",
    "\n",
    "comicsDf = comicsDf.reindex_axis(['title',\"description\", \"new_description\", \"full_description\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, reconstruimos la columna description para mantener la separación por frases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>new_description</th>\n",
       "      <th>full_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Mazing Man</td>\n",
       "      <td>mazing man is the title character of a comic b...</td>\n",
       "      <td>mazing_man man title_character comic_book_seri...</td>\n",
       "      <td>mazing man is the title character of a comic b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>711 (Quality Comics)</td>\n",
       "      <td>is a fictional superhero from the golden age o...</td>\n",
       "      <td>711_quality_comics fictional superhero golden_...</td>\n",
       "      <td>is a fictional superhero from the golden age o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abigail Brand</td>\n",
       "      <td>special agent special agent abigail brand is a...</td>\n",
       "      <td>abigail_brand special agent special agent abig...</td>\n",
       "      <td>special agent special agent abigail brand is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abin Sur</td>\n",
       "      <td>abin sur is a fictional character and a superh...</td>\n",
       "      <td>abin_sur abin sur fictional_character superher...</td>\n",
       "      <td>abin sur is a fictional character and a superh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abner Jenkins</td>\n",
       "      <td>abner ronald jenkins formerly known as the bee...</td>\n",
       "      <td>abner_jenkins abner ronald jenkins formerly_kn...</td>\n",
       "      <td>abner ronald jenkins formerly known as the bee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                                        description  \\\n",
       "0           'Mazing Man  mazing man is the title character of a comic b...   \n",
       "1  711 (Quality Comics)  is a fictional superhero from the golden age o...   \n",
       "2         Abigail Brand  special agent special agent abigail brand is a...   \n",
       "3              Abin Sur  abin sur is a fictional character and a superh...   \n",
       "4         Abner Jenkins  abner ronald jenkins formerly known as the bee...   \n",
       "\n",
       "                                     new_description  \\\n",
       "0  mazing_man man title_character comic_book_seri...   \n",
       "1  711_quality_comics fictional superhero golden_...   \n",
       "2  abigail_brand special agent special agent abig...   \n",
       "3  abin_sur abin sur fictional_character superher...   \n",
       "4  abner_jenkins abner ronald jenkins formerly_kn...   \n",
       "\n",
       "                                    full_description  \n",
       "0  mazing man is the title character of a comic b...  \n",
       "1  is a fictional superhero from the golden age o...  \n",
       "2  special agent special agent abigail brand is a...  \n",
       "3  abin sur is a fictional character and a superh...  \n",
       "4  abner ronald jenkins formerly known as the bee...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "APOSTROFOS = {\"aren't\" : \"are not\", \"can't\" : \"cannot\", \"couldn't\" : \"could not\", \n",
    "              \"didn't\" : \"did not\", \"doesn't\" : \"does not\", \"don't\" : \"do not\", \n",
    "              \"hadn't\" : \"had not\", \"hasn't\" : \"has not\", \"haven't\" : \"have not\", \n",
    "              \"he's\" : \"he is\", \"I'll\" : \"I will\", \"I'm\" : \"I am\", \"I've\" : \"I have\", \n",
    "              \"isn't\" : \"is not\", \"it's\" : \"it is\", \"let's\" : \"let us\", \"you've\" : \"you have\",\n",
    "              \"mustn't\" : \"must not\", \"shan't\" : \"shall not\", \"she'll\" : \"she will\", \n",
    "              \"she's\" : \"she is\", \"shouldn't\" : \"should not\", \"that's\" : \"that is\", \n",
    "              \"there's\" : \"there is\", \"they're\" : \"they are\", \"they've\" : \"they have\", \n",
    "              \"we're\" : \"we are\", \"we've\" : \"we have\", \"weren't\" : \"were not\", \n",
    "              \"what're\" : \"what are\", \"what's\" : \"what is\", \"what've\" : \"what have\", \n",
    "              \"where's\" : \"where is\", \"who're\" : \"who are\", \"who's\" : \"who is\", \n",
    "              \"who've\" : \"who have\", \"won't\" : \"will not\", \"wouldn't\" : \"would not\", \n",
    "              \"you're\" : \"you are\"} \n",
    "\n",
    "tree = ET.parse(\"Data Sets/Comics/all_characters.xml\")\n",
    "root = tree.getroot()\n",
    "index = 0\n",
    "for child in root:\n",
    "    if(child.tag.find(\"page\") >=0 ):\n",
    "        for grandchild in child:\n",
    "            if(grandchild.tag.find(\"title\") >= 0):\n",
    "                  title = grandchild.text\n",
    "            if(grandchild.tag.find(\"revision\") >= 0): \n",
    "                for grand2child in grandchild:\n",
    "                    if(grand2child.tag.find(\"text\") >= 0):\n",
    "                        #Obtener el texto del nodo\n",
    "                        text = grand2child.text.lower()\n",
    "                        #Eliminar las cadenas que inician en {{ seguidas de \n",
    "                        #cualquier cosa excepto }} y terminadas con }}\n",
    "                        text = re.sub('{{[^}}]*}}', '', text)\n",
    "                        #Misma idea, pero con el caracter especial \\[ \\] y Category:\n",
    "                        text = re.sub('\\[\\[Category:[^\\]\\]]*\\]\\]', '', text)\n",
    "                        #... y entre === ===\n",
    "                        text = re.sub('={3}[\\w]+={3}', '', text)\n",
    "                        #... y entre == ==\n",
    "                        text = re.sub('={2}[\\w]+={2}', '', text)\n",
    "                        #Extrae el texto de entre el código html... casi\n",
    "                        text = BeautifulSoup(text, \"lxml\").get_text() \n",
    "                        text = re.sub(\"<img([\\w\\W]+?)/?>\", \"\", text)\n",
    "                        #Eliminar direcciones http\n",
    "                        text = re.sub('\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', ' ', text) \n",
    "                        #... y direcciones de correo\n",
    "                        text = re.sub('[\\w\\.-]+@[\\w\\.-]+', \" \", text)\n",
    "                        #... y direcciones wikt*\n",
    "                        text = re.sub('\\[\\[wikt[^|]*|', '', text)\n",
    "                        #Eliminar puntos decorativos como en S.H.I.E.L.D.\n",
    "                        #text = text.replace(\".\",\"\")\n",
    "\n",
    "                        words = text.split()\n",
    "                        #Reenplazar el usos de apostrofos\n",
    "                        texto = [APOSTROFOS[word] if word in APOSTROFOS else word for word in words]\n",
    "                        texto = \" \".join(texto)\n",
    "                        #Eliminar otros caracteres no alfabéticos\n",
    "                        texto = re.sub(\"[^\\w*\\. +]\", \" \", texto)\n",
    "                        texto = re.sub(\"[\\d]\", \" \", texto)\n",
    "                        texto = re.sub(\" *\\.\", \".\", texto)\n",
    "                        texto = re.sub(\"(\\w)\\.(\\w)\\. \", r'\\1\\2 ', texto)\n",
    "                        #Eliminar palabras repetidas consecutivas\n",
    "                        words = re.sub(r'\\b(\\w+)(\\s+\\1\\b)+', r'\\1', texto).split()\n",
    "                        texto = \" \".join(words) \n",
    "                        \n",
    "        comicsDf.loc[index, \"full_description\"] = texto\n",
    "        index = index + 1\n",
    "\n",
    "display(comicsDf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mazing man is the title character of a comic book series created by bob rozakis and stephen destefano and published by dc comics. the series ran for twelve issues in with additional special issues in and. in addition mazing man had an origin story in secret origins and an original one page story that appeared in an ad in comics buyer s guide. series overview the mazing man series depicts the misadventures of sigfried horatio hunch iii a benignly deranged little man in queens new york queens new york city new york state new york who dresses in a homemade costume and performs deeds like unclogging drains and watching out for local children. viewed as a harmless kook by his neighbors he saves a child from being hit by a truck in the first issue earning him some respect and notoriety not to mention a steady stream of appreciation and food from the mother in subsequent issues. maze tends to sing simon and garfunkel songs when struck on the head. his best friend is denton fixx a writer for bc comics who looks like a beagle. hunch is a millionaire having won first place in a magazine subscription company s sweepstakes. after winning the prize he felt obligated to subscribe to all of the company s magazines. as a result he receives a staggering load of publications daily including the pornographic magazine s that he genuinely reads only for the articles. he does not keep his wealth a secret per se he simply does not mention it and does not live an opulent lifestyle. his friends are unaware of his financial success. the original series although highly acclaimed was short lived. however comics artist frank miller comics frank miller admired the series. eager to help the property survive miller contributed a cover with the lead characters of the extremely popular mini series batman the dark knight returns for the last issue. the resulting exposure created enough interest for subsequent one shot comics one shot issues. a back up feature zoot sputnik appeared for several issues drawn by fred hembeck and ostensibly written by denton fixx it was supposed to be the book fixx wrote for bc comics. it was a parody of the golden age of comic books golden age narrative style where stories had no between issue continuity zoot and his team were space adventurers in one issue and cowboys in the next. the team s dog received a shock of energy and gained the ability to remember their disparate adventures. this was denton s attempt to introduce continuity to the book but it was met with disapproval by his editor. mazing man is one of a handful of dc titles to publish an issue not featuring the comics code authority stamp of approval while it was active. in the issue writer s block denton is stuck for a story and all his friends give their ideas. one of them dealt with an army of zombie s. although there was no gore or violence any mention of the living dead specifically the use of the word zombie was forbidden by the comics code. the issue was released without the stamp with no publicity positive or negative. much later in the ambush bug year none miniseries mazing man in the same nonsensical way of the series is revealed to be on death row. other characters denton fixx maze s best friend. writer for bc comics. looks like a beagle. brenda valentine a rising star at a local advertising agency. she is married to eddie valentine. eddie valentine assistant to the assistant manager at the south richmond bank. promoted to assistant manager in issue september the bank job or by hook or by crook married to brenda. baseball player and gold glove winner at john quincy high school. kp watson denton s human looking half sister. guido garibaldi the jock simpleton who lives in the same building as denton maze eddie and brenda. he works in three shoe stores and spends most of his time wondering which one he is called in sick at drinking beer and hopelessly pursuing women. sgt. muldavey a local police officer who is plagued by maze s heroics. mrs. costinas landlady of maze denton and kp most often seen sweeping the front steps of their building. never smiles and usually grunts at all passersby. helenita trialdo a baby whose appearances revolve around her lack of hair. senora tiraldo helenita s mother. walter vanderplatz eddie s supervisor at the south richmond bank. more than a bit of a stuffed shirt. in other media * mazing man appears in the animated series batman the brave and the bold episode four star spectacular voiced by tom kenny. in the kitty catastrophe segment he is the accident prone petsitting catsitter for a couple named owen and fiona. it is apparent that batman is his favorite superhero and the inspiration for his costume. see also * list of dc comics publications external links * mazing man at don markstein s toonopedia. archived from the original on february. * bobrozakis.blogspot.com category dc comics titles category comics debuts category comics characters introduced in category humor comics category fictional characters with schizophrenia category fictional characters from new york city'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(comicsDf.loc[0].full_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos los primeros 50 registros, para facilitar el análisis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>new_description</th>\n",
       "      <th>full_description</th>\n",
       "      <th>tagged_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Mazing Man</td>\n",
       "      <td>mazing man is the title character of a comic b...</td>\n",
       "      <td>mazing_man man title_character comic_book_seri...</td>\n",
       "      <td>mazing man is the title character of a comic b...</td>\n",
       "      <td>[(promoted, VBN), (receives, VBZ), (remember, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>711 (Quality Comics)</td>\n",
       "      <td>is a fictional superhero from the golden age o...</td>\n",
       "      <td>711_quality_comics fictional superhero golden_...</td>\n",
       "      <td>is a fictional superhero from the golden age o...</td>\n",
       "      <td>[(jail, NN), (uses, VBZ), (early, JJ), (friend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abigail Brand</td>\n",
       "      <td>special agent special agent abigail brand is a...</td>\n",
       "      <td>abigail_brand special agent special agent abig...</td>\n",
       "      <td>special agent special agent abigail brand is a...</td>\n",
       "      <td>[(potent, JJ), (features, VBZ), (mutant, NN), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abin Sur</td>\n",
       "      <td>abin sur is a fictional character and a superh...</td>\n",
       "      <td>abin_sur abin sur fictional_character superher...</td>\n",
       "      <td>abin sur is a fictional character and a superh...</td>\n",
       "      <td>[(uncle, VB), (injuries, NNS), (fear, NN), (ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abner Jenkins</td>\n",
       "      <td>abner ronald jenkins formerly known as the bee...</td>\n",
       "      <td>abner_jenkins abner ronald jenkins formerly_kn...</td>\n",
       "      <td>abner ronald jenkins formerly known as the bee...</td>\n",
       "      <td>[(ultimately, RB), (pack, NN), (romanova, JJ),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                                        description  \\\n",
       "0           'Mazing Man  mazing man is the title character of a comic b...   \n",
       "1  711 (Quality Comics)  is a fictional superhero from the golden age o...   \n",
       "2         Abigail Brand  special agent special agent abigail brand is a...   \n",
       "3              Abin Sur  abin sur is a fictional character and a superh...   \n",
       "4         Abner Jenkins  abner ronald jenkins formerly known as the bee...   \n",
       "\n",
       "                                     new_description  \\\n",
       "0  mazing_man man title_character comic_book_seri...   \n",
       "1  711_quality_comics fictional superhero golden_...   \n",
       "2  abigail_brand special agent special agent abig...   \n",
       "3  abin_sur abin sur fictional_character superher...   \n",
       "4  abner_jenkins abner ronald jenkins formerly_kn...   \n",
       "\n",
       "                                    full_description  \\\n",
       "0  mazing man is the title character of a comic b...   \n",
       "1  is a fictional superhero from the golden age o...   \n",
       "2  special agent special agent abigail brand is a...   \n",
       "3  abin sur is a fictional character and a superh...   \n",
       "4  abner ronald jenkins formerly known as the bee...   \n",
       "\n",
       "                                        tagged_words  \n",
       "0  [(promoted, VBN), (receives, VBZ), (remember, ...  \n",
       "1  [(jail, NN), (uses, VBZ), (early, JJ), (friend...  \n",
       "2  [(potent, JJ), (features, VBZ), (mutant, NN), ...  \n",
       "3  [(uncle, VB), (injuries, NNS), (fear, NN), (ar...  \n",
       "4  [(ultimately, RB), (pack, NN), (romanova, JJ),...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_comicsDf = comicsDf[:50].copy()\n",
    "train_comicsDf[\"tagged_words\"] = list(map(lambda row, words: list(set(\n",
    "    [w for w in nltk.pos_tag(nltk.word_tokenize(row)) if w[0] in words.split()])),\n",
    "                        train_comicsDf.full_description, train_comicsDf.new_description))\n",
    "\n",
    "display(train_comicsDf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevamente, hemos hecho el etiquetado a partir del texto completo y lo restringimos a las palabras del lexicón. Los tokens compuestos requieren un tratamiento adicional. El etiquetado de un documento ejemplo es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('promoted', 'VBN'), ('receives', 'VBZ'), ('remember', 'VB'), ('special', 'JJ'), ('shirt', 'NN'), ('batman', 'VBD'), ('written', 'VBN'), ('felt', 'VBD'), ('ideas', 'NNS'), ('enough', 'JJ'), ('three', 'CD'), ('manager', 'NN'), ('use', 'NN'), ('usually', 'RB'), ('although', 'IN'), ('spends', 'VBZ'), ('winner', 'NN'), ('agency', 'NN'), ('like', 'IN'), ('head', 'NN'), ('appeared', 'VBD'), ('issue', 'NN'), ('success', 'NN'), ('depicts', 'VBZ'), ('positive', 'JJ'), ('millionaire', 'NN'), ('disapproval', 'NN'), ('handful', 'NN'), ('one', 'CD'), ('rising', 'VBG'), ('popular', 'JJ'), ('energy', 'NN'), ('block', 'NN'), ('jock', 'NN'), ('whose', 'WP$'), ('team', 'NN'), ('costume', 'NN'), ('children', 'NNS'), ('created', 'VBD'), ('glove', 'NN'), ('articles', 'NNS'), ('miller', 'NN'), ('none', 'NN'), ('row', 'NN'), ('magazines', 'NNS'), ('violence', 'NN'), ('bit', 'NN'), ('fred', 'JJ'), ('richmond', 'NN'), ('job', 'NN'), ('baby', 'NN'), ('brenda', 'NN'), ('adventures', 'NNS'), ('man', 'NN'), ('continuity', 'NN'), ('john', 'NN'), ('married', 'VBN'), ('tom', 'JJ'), ('harmless', 'NN'), ('child', 'NN'), ('player', 'NN'), ('watson', 'JJ'), ('lives', 'VBZ'), ('unaware', 'JJ'), ('plagued', 'VBN'), ('inspiration', 'NN'), ('buyer', 'NN'), ('financial', 'JJ'), ('eddie', 'VBP'), ('dog', 'NN'), ('stream', 'NN'), ('ran', 'VBD'), ('first', 'JJ'), ('magazine', 'NN'), ('performs', 'NNS'), ('style', 'NN'), ('eddie', 'JJ'), ('voiced', 'VBN'), ('songs', 'NNS'), ('narrative', 'JJ'), ('front', 'JJ'), ('favorite', 'JJ'), ('forbidden', 'VBN'), ('introduce', 'VB'), ('external', 'JJ'), ('drawn', 'VBN'), ('guide', 'NN'), ('watching', 'VBG'), ('supposed', 'VBN'), ('quincy', 'NN'), ('back', 'RB'), ('heroics', 'NNS'), ('without', 'IN'), ('publicity', 'NN'), ('stuck', 'VBN'), ('admired', 'VBD'), ('active', 'JJ'), ('humor', 'NN'), ('result', 'NN'), ('women', 'NNS'), ('steps', 'NNS'), ('specifically', 'RB'), ('valentine', 'NN'), ('however', 'RB'), ('eager', 'JJ'), ('gold', 'NN'), ('book', 'NN'), ('dealt', 'FW'), ('grunts', 'NNS'), ('deranged', 'JJ'), ('catastrophe', 'NN'), ('lifestyle', 'NN'), ('word', 'NN'), ('food', 'NN'), ('human', 'JJ'), ('batman', 'NN'), ('dresses', 'VBZ'), ('published', 'VBN'), ('mention', 'VB'), ('spectacular', 'NN'), ('sgt', 'NN'), ('drains', 'NNS'), ('struck', 'NN'), ('attempt', 'NN'), ('give', 'VBP'), ('hook', 'NN'), ('met', 'VBN'), ('property', 'NN'), ('zombie', 'NN'), ('way', 'NN'), ('place', 'NN'), ('ostensibly', 'RB'), ('per', 'NN'), ('released', 'VBN'), ('authority', 'NN'), ('keep', 'VB'), ('time', 'NN'), ('stories', 'NNS'), ('accident', 'NN'), ('little', 'JJ'), ('eddie', 'VB'), ('genuinely', 'RB'), ('tends', 'VBZ'), ('zombie', 'NNP'), ('created', 'VBN'), ('stores', 'NNS'), ('feature', 'NN'), ('including', 'VBG'), ('secret', 'JJ'), ('truck', 'NN'), ('apparent', 'JJ'), ('category', 'NN'), ('city', 'NN'), ('beer', 'NN'), ('received', 'VBD'), ('four', 'CD'), ('survive', 'JJ'), ('saves', 'VBZ'), ('resulting', 'JJ'), ('help', 'VB'), ('respect', 'NN'), ('shock', 'NN'), ('ability', 'NN'), ('kitty', 'JJ'), ('local', 'JJ'), ('deeds', 'NNS'), ('winning', 'VBG'), ('miniseries', 'NNS'), ('guido', 'NN'), ('daily', 'JJ'), ('series', 'NN'), ('denton', 'NN'), ('never', 'RB'), ('mother', 'NN'), ('negative', 'JJ'), ('named', 'VBN'), ('featuring', 'VBG'), ('kenny', 'NN'), ('issues', 'NNS'), ('called', 'VBN'), ('publish', 'VB'), ('death', 'NN'), ('simply', 'RB'), ('friends', 'NNS'), ('living', 'NN'), ('characters', 'NNS'), ('batman', 'IN'), ('mention', 'NN'), ('lack', 'NN'), ('fixx', 'NN'), ('fixx', 'JJ'), ('hair', 'NN'), ('brenda', 'VB'), ('year', 'NN'), ('appearances', 'NNS'), ('additional', 'JJ'), ('prize', 'NN'), ('wealth', 'NN'), ('extremely', 'RB'), ('star', 'NN'), ('gained', 'VBD'), ('married', 'JJ'), ('crook', 'NN'), ('around', 'IN'), ('army', 'NN'), ('superhero', 'NN'), ('building', 'NN'), ('publications', 'NNS'), ('hit', 'VBN'), ('denton', 'JJ'), ('interest', 'NN'), ('acclaimed', 'VBN'), ('dead', 'JJ'), ('adventurers', 'NNS'), ('pursuing', 'VBG'), ('walter', 'NN'), ('brave', 'NN'), ('next', 'JJ'), ('story', 'NN'), ('stephen', 'JJ'), ('addition', 'NN'), ('approval', 'NN'), ('media', 'NNS'), ('stuffed', 'JJ'), ('viewed', 'VBN'), ('space', 'NN'), ('cover', 'NN'), ('comics', 'NNS'), ('reads', 'VBZ'), ('wondering', 'VBG'), ('links', 'NNS'), ('category', 'JJ'), ('looking', 'VBG'), ('couple', 'NN'), ('company', 'NN'), ('list', 'NN'), ('category', 'VBP'), ('works', 'VBZ'), ('editor', 'NN'), ('iii', 'VBP'), ('south', 'JJ'), ('segment', 'NN'), ('prone', 'NN'), ('baseball', 'NN'), ('subsequent', 'JJ'), ('exposure', 'NN'), ('bank', 'NN'), ('simon', 'NN'), ('assistant', 'NN'), ('contributed', 'VBD'), ('original', 'JJ'), ('wrote', 'VBD'), ('eddie', 'NN'), ('writer', 'NN'), ('live', 'VB'), ('highly', 'RB'), ('earning', 'VBG'), ('drinking', 'VBG'), ('parody', 'NN'), ('denton', 'VBP'), ('owen', 'NN'), ('one', 'NN'), ('sick', 'NN'), ('assistant', 'VB'), ('queens', 'JJ')]\n"
     ]
    }
   ],
   "source": [
    "print(train_comicsDf[\"tagged_words\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede observarse, aparecen también palabras mal clasificadas. Por ejemplo, para el caso de los adjetivos (el principal tipo de palabra para evaluar polaridad), obtenemos lo siguiente, para el conjunto completo de 50 registros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1476 \n",
      "\n",
      "['ian', 'ordinary', 'sam', 'instrumental', 'earths', 'amongst', 'mild', 'rid', 'context', 'consciousness', 'ultimo', 'inevitable', 'toei', 'comet', 'sympathetic', 'extrasensory', 'infant', 'anonymous', 'noir', 'angel', 'visited', 'non', 'bobbi', 'antagonistic', 'earlier', 'starhawk', 'queens', 'worthy', 'breakworld', 'lead', 'kitty', 'swan', 'futurist', 'dave', 'precise', 'potential', 'chinese', 'supervillain', 'contemporary', 'altered', 'large', 'injured', 'electromagnetic', 'geist', 'xorn', 'violent', 'cold', 'upcoming', 'nicieza', 'military', 'alchemax', 'deviant', 'homosexual', 'avenger', 'liz', 'breyfogle', 'aggressive', 'indian', 'arrow', 'kinetic', 'moral', 'deadpool', 'hard', 'mikaboshi', 'storyline', 'nihilo', 'quick', 'explained', 'odin', 'bug', 'kirk', 'tyrant', 'likely', 'stereotypical', 'sole', 'unofficial', 'mach', 'near', 'temporary', 'airborne', 'metropolis', 'liberty', 'unpublished', 'survive', 'tangent', 'future', 'extensive', 'unpredictable', 'lobo', 'corrupt', 'designated', 'assassin', 'constant', 'wyatt', 'possible', 'winged', 'foreign', 'tormented', 'gold', 'mainstream', 'checkmate', 'reborn', 'told', 'hal', 'planetary', 'actor', 'ernie', 'comatose', 'private', 'infinity', 'torn', 'pratt', 'leather', 'anthropomorphic', 'russian', 'prototype', 'graphic', 'centaur', 'male', 'sleep', 'florida', 'birthday', 'annual', 'terrorist', 'seventh', 'unusual', 'viral', 'external', 'daredevil', 'crimson', 'concrete', 'little', 'stamina', 'starheart', 'parallel', 'organic', 'western', 'exact', 'final', 'dragon', 'bold', 'yellow', 'tremendous', 'december', 'countless', 'indicia', 'sustained', 'willing', 'satirical', 'suspect', 'entire', 'aware', 'injustice', 'later', 'fit', 'clear', 'capable', 'superhuman', 'early', 'texas', 'reintroduced', 'sexual', 'paramilitary', 'andrea', 'installed', 'xandarian', 'suicide', 'sorry', 'false', 'normal', 'friday', 'otherdimensional', 'realistic', 'shield', 'deadly', 'unconscious', 'red', 'mystic', 'latest', 'fred', 'isbn', 'category', 'nypd', 'quiet', 'animated', 'reader', 'tony', 'assemble', 'referred', 'eponymous', 'faster', 'onslaught', 'fight', 'sporadic', 'nyx', 'pleased', 'anderson', 'captured', 'tech', 'ezekiel', 'destiny', 'combined', 'obscure', 'plotted', 'subsequent', 'web', 'english', 'innocent', 'hall', 'ups', 'middle', 'shattered', 'morituri', 'intense', 'technical', 'accepted', 'dangerous', 'closest', 'narrative', 'formal', 'bullied', 'deranged', 'writer', 'international', 'older', 'psychotic', 'alien', 'purple', 'unable', 'immortal', 'wealthy', 'armor', 'favorite', 'bio', 'immense', 'read', 'radian', 'topaz', 'witch', 'lady', 'disembodied', 'deceased', 'sensory', 'psionic', 'darkness', 'ninja', 'paranormal', 'dcu', 'ultimatum', 'manifest'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "jj_comics = []\n",
    "for row in train_comicsDf[\"tagged_words\"]:\n",
    "    for word in row: \n",
    "        if 'JJ' in word[1]: \n",
    "            jj_comics.append(word[0])\n",
    "jj_comics = list(set(jj_comics))\n",
    "\n",
    "print(len(jj_comics), \"\\n\")\n",
    "print(jj_comics[:250], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos el mismo análisis utilizando `review` y `new_review` como base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_comicsDf[\"tagged_words2\"] = list(map(lambda row, words: list(set(\n",
    "    [w for w in nltk.pos_tag(nltk.word_tokenize(row)) if w[0] in words.split()])),\n",
    "                        train_comicsDf.description, train_comicsDf.new_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diferencias con 'description'\n",
      ": {'heist', 'abigail', 'reintroduced', 'meanwhile', 'corporeal', 'cover', 'helen', 'eddie', 'hate', 'benjamin', 'missed', 'devastated', 'june', 'forever', 'ann', 'spidey', 'margali', 'regardless', 'eager', 'lucas', 'carol', 'birthday', 'chemical', 'consciousness', 'rom', 'running', 'ben', 'alias', 'magik', 'spectacular', 'nevertheless', 'weakened', 'cyborg', 'hair', 'pixie', 'weapon', 'police', 'ups', 'resulting', 'kill', 'damon', 'pistol', 'stamina', 'thea', 'beast', 'retrieved', 'mutated', 'thorn', 'dan', 'born', 'infected'}\n",
      "\n",
      "Al revés:\n",
      " {'katie', 'upon', 'darren', 'leslie', 'mask', 'cassaday', 'readership', 'july', 'arctic', 'publication', 'strongbow', 'starlin', 'shanna', 'nov', 'rogue', 'hobgoblin', 'newsaramacom', 'survival', 'dec', 'sword', 'appear', 'website', 'degree', 'forehead', 'dr', 'austin', 'malebolgia', 'slingshot', 'harris', 'thomas', 'hive', 'develops', 'faithful', 'sep', 'octavius', 'braddock', 'collar', 'apollo', 'helmet', 'guide', 'trio', 'detroit', 'hunger', 'logic', 'detailed', 'atalanta', 'korvac', 'multiverse', 'skin', 'mantle', 'bros', 'included', 'thereafter', 'arrested', 'clash', 'armageddon', 'god', 'bear', 'feb', 'jpg', 'fortress', 'fujikawa', 'conquest', 'ritchie', 'atlantis', 'heven', 'exile', 'lyle', 'sekowsky', 'blob', 'bride', 'slave', 'aug', 'mayday', 'kaine', 'oct'}\n"
     ]
    }
   ],
   "source": [
    "jj_comics2 = []\n",
    "for row in train_comicsDf[\"tagged_words2\"]:\n",
    "    for word in row: \n",
    "        if 'JJ' in word[1]: \n",
    "            jj_comics2.append(word[0])\n",
    "print(\"Diferencias con 'description'\\n:\", set(jj_comics)-set(jj_comics2))\n",
    "\n",
    "print(\"\\nAl revés:\\n\", set(jj_comics2)-set(jj_comics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un análisis detallado arroja las siguientes palabras etiquetadas como adjetivos, siendo nombres (y, de paso, algunas palabras inútiles):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras mal etiquetadas como Adjetivo: 461\n"
     ]
    }
   ],
   "source": [
    "wrong_jjs = ['nose', 'august', 'pistols', 'larry', 'brian', 'episode', 'earth', 'xorn', \n",
    "            'toei', 'gamma', 'ogord', 'underworld', 'thunderbolts', 'wolverine', 'dave',\n",
    "            'morlun', 'text', 'amon', 'sam', 'vol', 'manhattan', 'tom', 'starman', 'cho', \n",
    "            'anderson', 'ray', 'hourman', 'collar', 'amy', 'francine', 'john', 'sid', \n",
    "            'beak', 'stephen', 'armstrong', 'bucky', 'edward', 'obsidian', 'superman',\n",
    "            'thomas', 'mexico', 'deadpool', 'roderick', 'csa', 'newsarama', 'sabretooth', \n",
    "            'terry', 'texas', 'fabian', 'blackthorn', 'chicago', 'thor', 'friday', 'oct', \n",
    "            'mary', 'virginia', 'september', 'november', 'austin', 'pen', 'july', 'liz',  \n",
    "            'andrea', 'david', 'braddock', 'lexcorp', 'magus', 'flatman', 'werewolf', \n",
    "            'lana', 'entropy', 'steve', 'thanagar', 'starheart', 'website', 'sebastian', \n",
    "            'jean', 'fujikawa', 'cameron', 'lobo', 'corps', 'sorceress', 'abe', 'feb', \n",
    "            'spyder', 'leslie', 'romanova', 'bobbi', 'january', 'manga', 'erik', 'equal',\n",
    "            'ollie', 'sep', 'zar', 'surtur', 'hobgoblin', 'marcus', 'comet', 'blacklight', \n",
    "            'nighthawk', 'marvel', 'spaceship', 'chest', 'gaiman', 'west', 'malebolgia', \n",
    "            'breyfogle', 'athena', 'corazon', 'cosmo', 'anya', 'superboy', 'archive',  \n",
    "            'america', 'workshop', 'fox', 'gun', 'nyx', 'object', 'pratt', 'germany', \n",
    "            'parallax', 'arin', 'mephisto', 'millennium', 'agent', 'bug', 'lionel', \n",
    "             'nihilo', 'stargirl', 'onslaught', 'madelyne', 'clark', 'stark', 'venom',\n",
    "            'hercules', 'legs', 'giganta', 'americop', 'heven', 'february', 'mikaboshi', \n",
    "            'batman', 'gary', 'saga', 'trask', 'ajax', 'gog', 'katie', 'sinestro',  \n",
    "            'quasar', 'emma', 'gyrich', 'universe', 'nazi', 'frank', 'ian', 'quicksilver', \n",
    "            'scott', 'alex', 'kaine', 'gamora', 'miss', 'gilbert', 'sword', 'jeffrey',  \n",
    "            'ernie', 'beatty', 'donna', 'girl', 'neil', 'lieutenant', 'assassin', 'dec',\n",
    "            'jake', 'watson', 'simon', 'retcon', 'december', 'azazel', 'lee', 'nicieza', \n",
    "            'jessica', 'atlantis', 'centaur', 'nicholas', 'storyline', 'aug', 'hal',  \n",
    "            'damian', 'dc', 'alchemax', 'demon', 'arizona', 'excalibur', 'rodriguez',  \n",
    "            'dr', 'odin', 'andromeda', 'greg', 'lake', 'toy', 'steven', 'hive', 'thanos', \n",
    "            'gwen', 'helmet', 'xandarian', 'ganthet', 'alanna', 'wooden', 'atalanta',  \n",
    "            'smallville', 'morituri', 'daredevil', 'cat', 'bros', 'queens', 'dragon',  \n",
    "            'usa', 'amanda', 'johnny', 'schwartz', 'galactus', 'bio', 'nintendo', 'sandi',\n",
    "            'tamaran', 'blob', 'duncan', 'roger', 'exile', 'liaison', 'hit', 'dcu',\n",
    "            'arnold', 'god', 'sophie', 'angels', 'norman', 'teammate', 'fred', 'geist', \n",
    "            'nov', 'superwoman', 'magneto', 'lady', 'thanagarian', 'kirk', 'jordan', \n",
    "            'web', 'lonnie', 'gemworld', 'bruce', 'boy', 'ultraverse', 'april', 'angela', \n",
    "            'omac', 'kirby', 'abin', 'file', 'illyana', 'uatu', 'asgard', 'alfred',  \n",
    "            'azrael', 'wade', 'francis', 'urich', 'scorpio', 'octavius', 'ursa', 'wilson', \n",
    "            'loki', 'hawkeye', 'osborn', 'darhk', 'elseworlds', 'verse', 'terrible', \n",
    "            'christopher', 'spider', 'bullseye', 'arrow', 'earths', 'alexander', 'lex', \n",
    "            'sega', 'shaw', 'sunpyre', 'witch', 'imperiex', 'ezekiel', 'titus', 'luther', \n",
    "            'owlman', 'michael', 'banshee', 'aminedi', 'galaxy', 'lantern', 'everett', \n",
    "            'library', 'wyatt', 'tony', 'xavier', 'pyreus', 'darren', 'nightcrawler',  \n",
    "            'apollo', 'clash', 'detroit', 'lyle', 'wizard', 'namor', 'task', 'adam',  \n",
    "            'doug', 'fantasy', 'florida', 'non', 'bubble', 'detective', 'angel',  \n",
    "            'amadeus', 'eclipso', 'bob', 'eric', 'natalia', 'friedrich', 'ous', 'pet',  \n",
    "            'writer', 'cloud', 'outlaws', 'abyss', 'insect', 'krypto', 'ghaur', 'alpha',  \n",
    "            'hawkman', 'grant', 'robin', 'starhawk', 'delphyne', 'archaeology', 'allan', \n",
    "            'armageddon', 'andy', 'doomsday', 'pattern', 'chief', 'maddy', 'pavitr',  \n",
    "            'fixx', 'pandora', 'team', 'robert', 'seth', 'daniel', 'queen', 'actor',  \n",
    "            'metal', 'mahmud', 'wall', 'showcase', 'dick', 'gil', 'luis', 'science', \n",
    "            'costume', 'batwoman', 'reader', 'matthew', 'latter', 'susan', 'fatigue', \n",
    "            'kevlar', 'sean', 'omega', 'metropolis', 'sandman', 'lisa', 'mordru', 'swan',\n",
    "            'gina', 'harold', 'huntress', 'multiverse', 'kyle', 'dale', 'korvac', 'bride', \n",
    "            'alan', 'sister', 'shanna', 'jeremy', 'hydra', 'denton', 'peter', 'telepathy', \n",
    "            'nick', 'rebirth', 'apocalypse', 'sur', 'skaar', 'pretty', 'develops', 'ivan', \n",
    "            'denny', 'mangaverse', 'longtime', 'nanobot', 'october', 'ultron', 'kitty',\n",
    "            'atom', 'terrorist', 'flesh', 'albert', 'sepulchre', 'stewart', 'gotham', \n",
    "            'mother', 'mantle', 'ellen', 'harris', 'ambush', 'citizen', 'hulk', 'ritchie',  \n",
    "            'injustice', 'stakar', 'tim', 'orb', 'category', 'saturday', 'nephew', 'dog',\n",
    "            'mine', 'nextwave', 'planet', 'ann', 'magik', 'margali', 'amaya', 'dan', \n",
    "            'enclave', 'portal', 'warlock', 'keown', 'thea', 'oberoi', 'pistol', 'rom',  \n",
    "            'lucas', 'knight', 'hall', 'cyborg']\n",
    "print(\"Palabras mal etiquetadas como Adjetivo:\", len(wrong_jjs))\n",
    "\n",
    "useless_words = ['newsaramacom', 'iii', 'unbeknownst', 'hepzibah', 'copyright', 'toonopedia', 'jpg',  \n",
    "                  'alt', 'jsa', 'jla', 'pip', 'isbn', 'nypd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reemplazamos estas etiquetas en nuestra base de datos (el *dataframe* `train_comicsDf`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1071 \n",
      "\n",
      "['christian', 'gotham', 'ordinary', 'familiar', 'fastest', 'undone', 'aleta', 'green', 'amongst', 'mild', 'villainous', 'perspective', 'instrumental', 'evil', 'additional', 'larger', 'standard', 'america', 'disillusioned', 'visual', 'malicious', 'captive', 'intellectual', 'costumed', 'rid', 'alternative', 'context', 'self', 'consciousness', 'ultimo', 'internal', 'last', 'specific', 'inevitable', 'super', 'higher', 'possess', 'sympathetic', 'extrasensory', 'futuristic', 'brutal', 'shot', 'botched', 'pixie', 'functioning', 'fictional', 'infant', 'android', 'diplomatic', 'anonymous', 'reminiscent', 'difficult', 'noir', 'connected', 'korean', 'mohawk', 'sixteen', 'angel', 'second', 'giant', 'next', 'invulnerable', 'rebellious', 'born', 'driving', 'visited', 'current', 'endless', 'wounded', 'firelord', 'uncredited', 'strongest', 'federal', 'antagonistic', 'uninhabited', 'satisfied', 'darkest', 'prey', 'unfortunate', 'hyper', 'formidable', 'earlier', 'radical', 'primary', 'less', 'spidey', 'southern', 'worthy', 'breakworld', 'lead', 'perfect', 'mutant', 'anniversary', 'favored', 'absolute', 'united', 'ord', 'new', 'harold', 'monthly', 'original', 'futurist', 'renowned', 'controversial', 'precise', 'potential', 'light', 'unknown', 'chinese', 'francine', 'supervillain', 'doomed', 'good', 'horrible', 'spiritual', 'contemporary', 'altered', 'friendly', 'prime', 'seek', 'large', 'injured', 'electromagnetic', 'everyman', 'loyal', 'quest', 'relaunched', 'resistant', 'ballistic', 'impressive', 'violent', 'cold', 'upcoming', 'unsuccessful', 'unexplained', 'meanwhile', 'mortal', 'revamped', 'gigantic', 'thirteen', 'military', 'magnetic', 'deviant', 'strong', 'enigmatic', 'guilty', 'fresh', 'married', 'demonic', 'interested', 'avenger', 'civilian', 'homosexual', 'bulletproof', 'canonical', 'aggressive', 'abused', 'indian', 'lockheed', 'beetle', 'public', 'supreme', 'reimagined', 'eternal', 'cosmic', 'cybernetic', 'gifted', 'advanced', 'experimental', 'uncertain', 'empty', 'weaker', 'sharp', 'kinetic', 'moral', 'exclusive', 'classic', 'deadpool', 'hard', 'close', 'vulnerable', 'enraged', 'sonic', 'global', 'competent', 'able', 'odd', 'digital', 'lan', 'tactical', 'quick', 'rapid', 'masked', 'servant', 'explained', 'present', 'destroyed', 'protected', 'invisible', 'connect', 'infected', 'total', 'distinct', 'upper', 'come', 'neural', 'undercover', 'blue', 'common', 'intergalactic', 'tyrant', 'natural', 'animal', 'artist', 'prolonged', 'excello', 'illegal', 'electronic', 'robotic', 'opal', 'likely', 'extreme', 'stereotypical', 'uniform', 'universe', 'sole', 'overweight', 'unofficial', 'rich', 'eager', 'wonder', 'militant', 'mach', 'unwilling', 'incident', 'ben', 'near', 'amethyst', 'conscious', 'correct', 'temporary', 'airborne', 'understanding', 'female', 'depicted', 'wide', 'multi', 'orphaned', 'illegitimate', 'elite'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_nn = []\n",
    "for i, row in zip(range(len(train_comicsDf)), train_comicsDf.tagged_words):\n",
    "    for j, word in zip(range(len(row)), row): \n",
    "        if word[0] in useless_words: \n",
    "            row.pop(j)\n",
    "        elif word[0] in wrong_jjs and 'JJ' in word[1]:\n",
    "            row.pop(j)\n",
    "            new_nn.append((word[0], 'NN')) \n",
    "            \n",
    "    train_comicsDf.loc[i, \"tagged_words\"] = row + new_nn\n",
    "\n",
    "jj_comics = []\n",
    "for row in train_comicsDf[\"tagged_words\"]:\n",
    "    for word in row: \n",
    "        if 'JJ' in word[1]: \n",
    "            jj_comics.append(word[0])\n",
    "jj_comics = list(set(jj_comics))\n",
    "\n",
    "print(len(jj_comics), \"\\n\")\n",
    "print(jj_comics[:250], \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
