{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![agents](images/header.jpg)\n",
    "# Análisis sintáctico\n",
    "### Ramón Soto C. [(rsotoc@moviquest.com)](mailto:rsotoc@moviquest.com/)\n",
    "[ver en nbviewer](http://nbviewer.ipython.org/github/rsotoc/nlp/blob/master/Introducción.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](images/blank.png)\n",
    "## Definición\n",
    "\n",
    "El objetivo del análisis sintáctico es analizar un flujo de caracteres, o de tokens, para identificar la estructura en frases del mensaje.\n",
    "\n",
    "![](images/nlp02d.png)\n",
    "\n",
    "En las aproximaciones al procesamiento de lenguaje natural basada en [lingüísticas generativas](https://en.wikipedia.org/wiki/Generative_grammar), el análisis sintáctico suele referirse a encontrar la estructura gramatical del texto en términos de las frases que lo conforman. Esta es posiblemente el área mejor establecida en el campo de procesamiento de lenguaje natural gracias a los avances realizados en el área de gramáticas formales/generativas.\n",
    "\n",
    "### Gramática\n",
    "\n",
    "La Real Academia de la Lengua define la [gramática](drive.google.com/drive/folders/0B3Xu6MK8u7nbWFVIai04SWhMMXM) como:\n",
    "\n",
    "> 3 f. Parte de la lingüística que estudia los elementos de una lengua, así como la forma en que estos se organizan y se combinan. \n",
    "\n",
    "La gramática se enfoca en las categorías a las que pertenece cada elemento lingüístico (no en el significado, que corresponde a la semántica) para comprender las formas en que estos elementos se pueden combinar para formar estructuras, oraciones y frases (a lo que llamamos sintaxis).\n",
    "\n",
    "## Gramáticas formales\n",
    "\n",
    "Una gramática (formal) se define como la tupla\n",
    "\n",
    "$$G = (N,\\Sigma,P,S)$$\n",
    "\n",
    "donde\n",
    "\n",
    "* $N$ es un conjunto finito de símbolos  no-terminales (variables a substituir).\n",
    "* $\\Sigma$ es un conjunto finito de símbolos terminales llamado el *alfabeto* o *vocabulario*. En el caso de gramáticas asociadas a los lenguajes naturales, el vocabulario es usualmente un conjunto de letras, signos, palabras, morfemas, sonidos y otros tokens.\n",
    "* $S\\in N$ es el *símbolo inicial*, es decir el símbolo no terminal desde donde se inicia la construcción de una *'frase'*\n",
    "* $P = \\{\\alpha \\to \\beta\\ \\vert\\ \\alpha \\in (N \\cup \\Sigma)^* N (N \\cup \\Sigma)^*, \\beta \\in (N \\cup \\Sigma)^* \\}$ es un conjunto finito de *reglas de producción*, es decir, reglas que definen cómo pueden irse reemplazando los símbolos no-terminales, desde el símbolo inicial, hasta tener una frase terminada.\n",
    "\n",
    "La forma de las reglas de producción determinan el tipo de gramática y el correspondiente autómata. \n",
    "\n",
    "Cada gramática está asociado a un tipo de *autómata* que sería, en realidad, el responsable de reconocer los patrones generables por la gramática correspondiente. Un lenguaje, es el conjunto de secuencias o cadenas sobre $\\Sigma$ (es decir, $L(G) \\subseteq \\Sigma^*$) que pueden ser generadas por una gramática dada $G$. \n",
    "\n",
    "Los tipos principales de gramáticas/lenguajes/autómata están definidos mediante la jerarquía de Chomsky:\n",
    "\n",
    "Gramática | Lenguaje | Autómata\n",
    "-| \n",
    "Tipo 0 | Recursivamente enumerable |\tMáquina de Turing\n",
    "Tipo 1 | Dependiente del contexto | Autómata linealmente acotado\n",
    "Tipo 2 | Independiente del contexto | Autómata de pila\n",
    "Tipo 3 | Regular | Autómata finito\n",
    "\n",
    "El orden del tipo de gramática, en esta jerarquía, aumenta conforme se agregan restricciones a las reglas de producción y se delimita con ello las producciones que conforman el lenguaje correspondiente. \n",
    "\n",
    "### Gramáticas sin restricciones\n",
    "Las gramáticas de tipo 0, o *gramáticas sin restricciones*, son gramáticas en las que las reglas de producción, $\\alpha \\to \\beta$, presentan la única restricción (ya establecida) de que el lado izquierdo de la regla contenga al menos un símbolo no terminal. Los lenguajes que produce una gramática sin restricciones son denominados *Turing-computables* o *parcialmente decidibles*. Esto porque el autómata que los reconoce puede no terminar nunca cuando la cadena no pertenece al lenguaje (entrando en un loop infinito). Esta característica hace poco viable su aplicación práctica, sin embargo, son de gran utilidad teórica.\n",
    "\n",
    "### Gramáticas sensibles al contexto\n",
    "Las gramáticas de tipo 1, o *gramáticas sensibles al contexto*, se obtienen al agregar restricciones a las gramáticas de tipo 0. Estas gramáticas tienen reglas de la forma $\\alpha A\\beta \\rightarrow \\alpha\\gamma\\beta$, con la condición de que $\\gamma$ no sea la cadena vacía, es decir, $\\gamma \\ne \\epsilon$. La regla $S\\to\\epsilon$ es permitida sólo si $S$ no aparece en el lado derecho de ninguna regla. Las gramáticas sensibles al contexto fueron propuestas por Chomsky para describir las gramáticas en lenguajes naturales, sin embargo, existe una gran discusión hasta dónde se cumple este objetivo. Las restricciones sobre las gramáticas de tipo 1 las hacen más tratables que las gramáticas sin restricciones, pero siguen teniendo una complejidad *PSPACE-complete*. \n",
    "\n",
    "[![](images/complexity.png)](http://www.cs.virginia.edu/~robins/The_Limits_of_Quantum_Computers.pdf)\n",
    "\n",
    "### Gramáticas libres de contexto\n",
    "Las gramáticas de tipo 2, o *gramáticas libres de contexto*. Estas gramáticas tienen reglas de la forma $A\\rightarrow \\gamma$. Estas gramáticas son la base de los lenguajes de programación y, por lo tanto, de los analizadores sintácticos (*parsers*). En ese punto, ya encontramos herramientas automáticas para análisis de frases, como la clase **CFG** del módulo [NLTK](http://www.nltk.org) de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.parse.generate import generate\n",
    "from nltk import CFG\n",
    "from IPython.display import Image, display  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos definir una gramática a partir de una cadena, de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> A\n",
    "    A -> 'a'A\n",
    "    A -> '{' B\n",
    "    B -> 'b'C\n",
    "    C -> '}'C\n",
    "    C -> 'c'C\n",
    "    C -> 'c'\n",
    "    \"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar)\n",
    "print(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta gramática permite generar cadenas formadas por una secuencia de letras 'a', seguida de una 'b' encerrada entre llaves y cualquier cantidad de letras 'c'. Por ejemplo, la cadena \"aa{b}cc\", se puede generar mediante esta gramática realizando una secuencia de pasos descrita en el siguiente árbol de generación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = \"aa{b}cc\"\n",
    "print(\"Árbol de generación de la cadena \\\"{}\\\"\".format(X))\n",
    "\n",
    "for tree in parser.parse(list(X)):\n",
    "    display(tree) # tree.draw() arroja una ventana emergente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente gramática genera expresiones algebraicas en las variables $x$, $y$ y $z$, en notación infija."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grammar_alg = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> 'x'\n",
    "    S -> 'y'\n",
    "    S -> 'z'\n",
    "    S -> S '+' S\n",
    "    S -> S '-' S\n",
    "    S -> S '*' S\n",
    "    S -> S '/' S\n",
    "    S -> '(' S ')'\n",
    "    \"\"\")\n",
    "\n",
    "parser_alg = nltk.ChartParser(grammar_alg)\n",
    "print(grammar_alg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y tratamos de generar la cadena $x + y * z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_alg1 = \"x + y * z\"\n",
    "print(\"Árbol de generación de la cadena \\\"{}\\\"\".format(X_alg1))\n",
    "\n",
    "for tree in parser_alg.parse(X_alg1.split()):\n",
    "    display(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que, al no haber reglas de precedencia, hay dos posibles formas de generar la cadena. Las reglas de precedencia son una forma de semántica, por lo que no corresponde a la fase de anáisis sintáctico (aunque es común realizar esa revisión en este paso).\n",
    "\n",
    "Las gramáticas libres de contexto permiten especificar y analizar la generación de lenguajes naturales. Consideremos, por ejemplo, la siguiente versión de una gramática del español:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "grammar_sp = nltk.CFG.fromstring(\"\"\"\n",
    "    ORACION -> SUJETO PREDICADO '.'\n",
    "    SUJETO -> FRASE_NOMINAL\n",
    "    FRASE_NOMINAL -> GRUPO_NOMINAL\n",
    "    FRASE_NOMINAL -> GRUPO_NOMINAL CALIFICATIVO\n",
    "    GRUPO_NOMINAL -> NOMBRE\n",
    "    GRUPO_NOMINAL -> ARTICULO NOMBRE\n",
    "    CALIFICATIVO -> CONJUNCION ORACION\n",
    "    CALIFICATIVO -> ADJETIVO\n",
    "    PREDICADO -> VERBO COMPLEMENTOS\n",
    "    COMPLEMENTOS -> DIRECTO INDIRECTO CIRCUNSTANCIAL\n",
    "    COMPLEMENTOS -> DIRECTO CIRCUNSTANCIAL\n",
    "    COMPLEMENTOS -> INDIRECTO CIRCUNSTANCIAL\n",
    "    COMPLEMENTOS -> CIRCUNSTANCIAL\n",
    "    CIRCUNSTANCIAL -> \n",
    "    DIRECTO -> FRASE_NOMINAL\n",
    "    INDIRECTO -> 'a' FRASE_NOMINAL\n",
    "    CIRCUNSTANCIAL -> PREPOSICION FRASE_NOMINAL\n",
    "    NOMBRE -> 'niña'\n",
    "    NOMBRE -> 'María'\n",
    "    NOMBRE -> 'comida'\n",
    "    NOMBRE -> 'parque'\n",
    "    ARTICULO -> 'la'\n",
    "    ARTICULO -> 'el'\n",
    "    VERBO -> 'pedía'\n",
    "    PREPOSICION -> 'en'\n",
    "    \"\"\")\n",
    "\n",
    "parser_sp = nltk.ChartParser(grammar_sp)\n",
    "print(grammar_sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta gramática permite generar frases como \"la niña pedía comida.\", \"la niña pedía comida en el parque.\" y \"*la niña pedía comida a María en el parque.*\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_sp = \"la niña pedía comida.\"\n",
    "print(\"Árbol de generación de la cadena \\\"{}\\\"\".format(X_sp))\n",
    "for tree in parser_sp.parse(word_tokenize(X_sp)):\n",
    "    display(tree) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X2_sp = \"la niña pedía comida en el parque.\"\n",
    "print(\"Árbol de generación de la cadena \\\"{}\\\"\".format(X2_sp))\n",
    "for tree in parser_sp.parse(word_tokenize(X2_sp)):\n",
    "    display(tree) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X3_sp = \"la niña pedía comida a María en el parque.\"\n",
    "print(\"Árbol de generación de la cadena \\\"{}\\\"\".format(X3_sp))\n",
    "for tree in parser_sp.parse(word_tokenize(X3_sp)):\n",
    "    display(tree) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque también permite generar frases como \"*la parque pedía parque en la parque.*\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X4_sp = \"la parque pedía parque en la parque.\"\n",
    "print(\"Árbol de generación de la cadena \\\"{}\\\"\".format(X4_sp))\n",
    "for tree in parser_sp.parse(word_tokenize(X4_sp)):\n",
    "    display(tree) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... y muchas otras frases sin sentido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.parse.generate import generate\n",
    "\n",
    "for sentence in generate(grammar_sp, n=20):\n",
    "    print(re.sub(\" \\.\", \".\", ' '.join(sentence)))\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos modificar ligeramente la gramática, agregando una regla adicional, para generar/reconocer una secuencia de frases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grammar2_sp = nltk.CFG.fromstring(\"\"\"\n",
    "    ORACION -> SUJETO PREDICADO '.' \n",
    "    ORACION -> ORACION ORACION\n",
    "    SUJETO -> FRASE_NOMINAL\n",
    "    FRASE_NOMINAL -> GRUPO_NOMINAL\n",
    "    FRASE_NOMINAL -> GRUPO_NOMINAL CALIFICATIVO\n",
    "    GRUPO_NOMINAL -> NOMBRE\n",
    "    GRUPO_NOMINAL -> ARTICULO NOMBRE\n",
    "    CALIFICATIVO -> CONJUNCION ORACION\n",
    "    CALIFICATIVO -> ADJETIVO\n",
    "    PREDICADO -> VERBO COMPLEMENTOS\n",
    "    COMPLEMENTOS -> DIRECTO INDIRECTO CIRCUNSTANCIAL\n",
    "    COMPLEMENTOS -> DIRECTO CIRCUNSTANCIAL\n",
    "    COMPLEMENTOS -> INDIRECTO CIRCUNSTANCIAL\n",
    "    COMPLEMENTOS -> CIRCUNSTANCIAL\n",
    "    CIRCUNSTANCIAL -> \n",
    "    DIRECTO -> FRASE_NOMINAL\n",
    "    INDIRECTO -> 'a' FRASE_NOMINAL\n",
    "    CIRCUNSTANCIAL -> PREPOSICION FRASE_NOMINAL\n",
    "    NOMBRE -> 'niña'\n",
    "    NOMBRE -> 'niño'\n",
    "    NOMBRE -> 'María'\n",
    "    NOMBRE -> 'comida'\n",
    "    NOMBRE -> 'parque'\n",
    "    ARTICULO -> 'la'\n",
    "    ARTICULO -> 'el'\n",
    "    VERBO -> 'pedía'\n",
    "    VERBO -> 'corría'\n",
    "    PREPOSICION -> 'en'\n",
    "    \"\"\")\n",
    "\n",
    "parser2_sp = nltk.ChartParser(grammar2_sp)\n",
    "\n",
    "X3_sp = \"\"\"la niña pedía comida a María. el niño corría en el parque. \"\"\"\n",
    "for tree in parser2_sp.parse(word_tokenize(X3_sp)):\n",
    "    display(tree) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El uso más directo del análisis sintáctico es la verificación de forma y estilo en un documento: ¿El documento está bien escrito, de acuerdo a alguna norma o estilo? ¿Los elementos de género y número están bien empleados? También es útil en la generación automática de lenguaje; en la creación automatizada, por ejemplo, de fregmentos de texto o en los sistemas de traducción.\n",
    "\n",
    "Otra posibilidad de uso es para la determinación del sentido más probable de [palabras homónimas](https://es.wikipedia.org/wiki/Homonimia), esto es palabras que aunque se escriben de la misma manera, tienen significados diferentes, particularmente en el caso de homonimia gramatical: vela, vino, coma, monto, etc.\n",
    "\n",
    "También puede ser de ayuda en la clasificación automatizada de los tokens en un lexicón."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gramáticas regulares\n",
    "\n",
    "Las gramática de tipo 3, o \"*gramáticas regulares*\", generan lenguajes regulares. En estas gramáticas el lado izquierdo de las reglas debe contener un sólo símbolo que debe ser un terminal, mientras que el lado derecho sólo puede contener un símbolo terminal, posiblemente seguido (o antecedido) de un símbolo no terminal o la cadena vacía, es decir, las reglas pueden ser del tipo $A\\to a$ o $A\\to aB$ (si es gramática regular por la derecha) o $A\\to\\epsilon$, siendo $a\\in\\Sigma, A,B\\in N$ y $\\epsilon$ la cadena vacía.\n",
    "\n",
    "Un uso muy exgendido de las gramáticas regulares es el reconocimiento de cadenas mediante expresiones regulares. Las expresiones regulares son descripciones sintéticas de lenguajes regulares\n",
    "\n",
    "Aunque en este curso emplearemos Python como lenguaje de programación, el uso de expresiones regulares es muy similar en otros lenguajes.\n",
    "\n",
    "### El módulo <code>re</code> de Python\n",
    "\n",
    "El módulo <code>re</code> de Python ofrece una colección de métodos para realizar operaciones sobre cadenas; los siguientes son algunos de los métodos en este módulo:\n",
    "\n",
    "#### <code>re.match(s, string)</code>: \n",
    "Determina si la cadena <code>string</code> inicia con la cadena <code>s</code>, por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "string = \"La oveja negra ya se ha juntado\\n\\\n",
    "a otras ovejas negras como él.\\n\\\n",
    "Como no hay hierba fresca en el prado\\n\\\n",
    "comen coronas de laurel.\"\n",
    "\n",
    "print(\"1.\", re.match(\"La oveja\", string))\n",
    "print(\"2.\", re.match(\"La oveja negra\", string))\n",
    "print(\"3.\", re.match(\"oveja\", string))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejemplo anterior, la función ha encontrado que la cadena *string* inicia con \"*La oveja*\" o con \"*La oveja negra*\", peor no con \"*oveja*\".\n",
    "\n",
    "#### <code>re.search(s, string)</code>: \n",
    "Busca si la cadena <code>s</code> es subcadena de <code>string</code> en cualquier punto. Regresa la primera ocurrencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"4.\", re.search(\"oveja\", string))\n",
    "print(\"5.\", re.search(\"coronas de laurel\", string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code>re.findall(s, string)</code>: \n",
    "Busca todas las ocurrencias de la cadena <code>s</code> en la cadena <code>string</code>, en cualquier punto y regresa las ocurrencias en una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"6.\", re.findall(\"oveja\", string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code>re.finditer(s, string)</code>: \n",
    "Busca todas las ocurrencias de la cadena <code>s</code> en la cadena de <code>string</code> y regresa las ocurrencias en un iterador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "it = re.finditer(\"oveja\", string)\n",
    "res_idx = 7\n",
    "\n",
    "for item in it:\n",
    "    print(\"{}. {}\".format(res_idx, item))\n",
    "    res_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code>re.sub(s, r, string[, count=0])</code>: \n",
    "Busca todas las ocurrencias de la cadena <code>s</code> en la cadena de <code>string</code> y reemplaza por la cadena <code>r</code>. El argumento opcional <code>count</code> define el número máximo de reemplazos. El valor cero indico \"*todas*\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "str0 = re.sub(\"oveja\", \"nave\", string)\n",
    "print(\"9.\", str0)\n",
    "\n",
    "str1 = re.sub(\"oveja\", \"nave\", string, count=1)\n",
    "print(\"\\n10.\", str1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificación de patrones mediante expresiones regulares\n",
    "\n",
    "La mayoría de los caracteres en una cadena son identificados de forma literal, como en el siguiente ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n11.\", re.sub(\"oveja\", \"OVEJA\", string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, muchas partes de un lenguaje natural (subconjuntos de construcciones lingüísticas) pueden describirse como lenguajes regulares y, por lo tanto, pueden ser descritas mediante expresiones regulares. Es decir, gran parte de las cadenas en un lenguaje natural puede ser descrita mediante expresiones regulares. Por ejemplo, consideremos la siguiente gramática:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grammar_reg = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> 'a' S\n",
    "    S -> 'b' B\n",
    "    B -> 'b' B\n",
    "    B -> A\n",
    "    A -> 'c' A\n",
    "    A -> \n",
    "    \"\"\")\n",
    "\n",
    "print(grammar_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta gramática genera cadenas del siguiente tipo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for sentence in generate(grammar_reg, depth=6):\n",
    "    print(''.join(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este conjunto de cadenas puede representarse como $\\{a^*b^+c^*\\}$, donde $x^*$ representa una subcadena formada por 0 o más repeticiones del caracter $x$, mientras que $x^+$ representa una subcadena formada por 1 o más repeticiones del caracter $x$. El símbolo especial $\\ ^*$ se denomina *clausura de Kleene* o *estrella Kleene*, mientras que $\\ ^+$ se denomina *cerradura/clausura/estrella positiva de Kleene*. \n",
    "\n",
    "Otros símbolos utilizados en expresiones regulares son:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Caracter |Resultado |\n",
    "|---|----|\n",
    "|**<code>'.'</code>** |El punto se empareja con cualquier caracter excepto el cambio de línea. Si se especifica la bandera <code>DOTALL</code> también empareja con el cambio de línea.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n12.\", re.sub(\".\", \"x\", string))\n",
    "\n",
    "print(\"\\n13. Incluyendo DOTALL:\\n{}\".format(re.sub(\".\", \"y\", string, flags=re.DOTALL)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Caracter |Resultado |\n",
    "|---|----|\n",
    "|**<code>'^'</code>** |Establece que la substitución sólo se hara al inicio de la cadena. Si se especifica la bandera <code>MULTILINE</code> también se realizará al inicio de cada nueva línea.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n14.\", re.sub(\"^.\", \"--\", string))\n",
    "\n",
    "print(\"\\n15. Incluyendo MULTILINE:\\n{}\".format(re.sub(\"^.\", \"--\", string, flags=re.MULTILINE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Caracter |Resultado |\n",
    "|---|----|\n",
    "|**<code>'\\A'</code>** | Establece que la substitución sólo se hara al inicio de la línea. No es afectado por la bandera <code>MULTILINE</code>.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n16.\", re.sub(\"\\A.\", \"--\", string))\n",
    "\n",
    "print(\"\\n17. Incluyendo MULTILINE:\\n{}\".format(re.sub(\"\\A.\", \"--\", string, flags=re.MULTILINE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Caracter |Resultado |\n",
    "|---|----|\n",
    "|**<code>'$'</code>** |Establece que la substitución sólo se hará al final de la cadena. Si se especifica la bandera <code>MULTILINE</code> también se realizará al final de cada línea.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n18.\", re.sub(\".$\", \"--\", string))\n",
    "\n",
    "print(\"\\n19. Incluyendo MULTILINE:\\n{}\".format(re.sub(\".$\", \"--\", string, flags=re.MULTILINE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Caracter |Resultado |\n",
    "|---|----|\n",
    "|**<code>'[]'</code>** | Define un conjunto de caracteres. Pueden ser individuales (<code>'[abc]'</code>); en rango (<code>'[a-d]'</code>), se puede incluir el signo - utilizando la secuencia de escape <code>'\\\\-'</code> o colocándolo al final del conjunto (<code>'[a-d\\-]'</code>). Caracteres especiales como  <code>'(', '+', '*', or ')'</code> pierden su significado dentro de los corchetes. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n20.\", re.sub(\"[abc]\", \"x\", string))\n",
    "\n",
    "print(\"\\n21. {}\".format(re.sub(\"[d-g]\", \"x\", string)))\n",
    "\n",
    "print(\"\\n22. {} -> {}\".format(\"--a oveja negra ya se ha juntado\",\n",
    "                          re.sub(\"[a-d\\-j]\", \"x\", \"--a oveja negra ya se ha juntado\")))\n",
    "\n",
    "print(\"\\n23. {} -> {}\".format(\"La estrella de Kleene (*)...\",\n",
    "                          re.sub(\"[(+*)]\", \"x\", \"La estrella de Kleene (*)...\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Caracter |Resultado |\n",
    "|---|----|\n",
    "|**<code>\\w</code>** | Empareja con cualquier caracter de palabra: Un caracter unicode, un ideograma, un dígito o el guión bajo. |\n",
    "|**<code>\\W</code>** | Empareja con cualquier caracter que NO sea un caracter de palabra. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n24. {} -> {}\".format(\"La estrella_de_Kleene (*)...\",\n",
    "                          re.sub(\"\\w\", \"a\", \"La estrella_de_Kleene (*)...\")))\n",
    "\n",
    "print(\"\\n25. {} -> {}\".format(\"La estrella_de_Kleene (*)...\",\n",
    "                          re.sub(\"\\W\", \"-\", \"La estrella_de_Kleene (*)...\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Caracter |Resultado |\n",
    "|---|----|\n",
    "|**<code>\\s</code>** | Empareja con cualquier caracter de espacio; cualquier separador unicode. |\n",
    "|**<code>\\S</code>** | Empareja con cualquier caracter que NO sea un caracter de espacio/separeador. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n26. {} -> {}\".format(\"La estrella_de_Kleene (*)...\",\n",
    "                          re.sub(\"\\w\", \"a\", \"La estrella_de_Kleene (*)...\")))\n",
    "\n",
    "print(\"\\n27. {} -> {}\".format(\"La estrella_de_Kleene (*)...\",\n",
    "                          re.sub(\"\\W\", \"-\", \"La estrella_de_Kleene (*)...\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Caracter |Resultado |\n",
    "|---|----|\n",
    "|**<code>\\num** | Hace referencia al grupo que aparece en el orden señalado por *num*. Cada grupo se define mediante paréntesis. <code>\\1</code> es, por ejemplo, el primer grupo que aparece en la expresión regular <code><([\\w]+).*>(.*?)<\\/\\1></code>. En este caso la diagonal <code>\\</code> se lee por separado de a etiqueta numérica, de manera que hay que utilizar cadenas en bruto (<code>r\"\\1\"</code>) o especificar que se trata del caracter diagonal (<code>\"\\\\\\1\"</code>).|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n28. {} -> {}\".format(\"La oveja oveja negra ya se ha juntado\", \n",
    "                              re.sub(r\"(\\w+)\\s+\\1\", \"\\\\1\", \"La oveja oveja negra ya se ha juntado\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n{} -> {}\".format(\"--a oveja negra ya se ha juntado\",\n",
    "                          re.sub(\"[a-d\\-j]\", \"x\", \"--a oveja negra ya se ha juntado\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.search('={3}[\\w]+={3}', \"EJEMPLO ===funciona==parece\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* URL's: <code>\\w+:\\/{2}[\\d\\w-]+(&#92;.[\\d\\w-]+)&#42;(?:(?:\\/[^\\s/]&#42;))&#42;</code>\n",
    "![](images/regex01.png)<br>\n",
    "\n",
    "* Tags de HTML: <code>(?i)<\\/?\\w+((\\s+\\w+(\\s&#42;=\\s&#42;(?:\\\".&#42;?\\\"|'.&#42;?'|[^'\\\">\\s]+))?)+\\s&#42;|\\s&#42;)\\/?></code>\n",
    "![](images/regex02.png)<br>\n",
    "\n",
    "* Passwords: <code>((?=.&#42;\\d)(?=.&#42;[a-z])(?=.&#42;[A-Z])(?=.&#42;[@#$%]).{6,20})</code>\n",
    "![](images/regex03.png)<br>\n",
    "\n",
    "* Tags de HTML: <code><([\\w]+).&#42;>(.&#42;?)<\\/\\1></code>\n",
    "![](images/regex04.png)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "<hr style=\"border-width: 3px;\">\n",
    "\n",
    "### Tarea 1\n",
    "\n",
    "Describa un problema de reconocimiento de patrones de su interés y explique por qué un modelo tradicional sería inapropiado para resolverlo (utilice la celda siguiente, en esta libreta, para presentar su problema seleccionado).\n",
    "\n",
    "**Fecha de entrega**: Viernes 20 de enero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
